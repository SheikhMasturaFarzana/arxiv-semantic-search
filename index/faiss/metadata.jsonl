{"arxiv_id":"2509.15217v1","title":"Generalizable Geometric Image Caption Synthesis","abstract":"Multimodal large language models have various practical applications that\ndemand strong reasoning abilities. Despite recent advancements, these models\nstill struggle to solve complex geometric problems. A key challenge stems from\nthe lack of high-quality image-text pair datasets for understanding geometric\nimages. Furthermore, most template-based data synthesis pipelines typically\nfail to generalize to questions beyond their predefined templates. In this\npaper, we bridge this gap by introducing a complementary process of\nReinforcement Learning with Verifiable Rewards (RLVR) into the data generation\npipeline. By adopting RLVR to refine captions for geometric images synthesized\nfrom 50 basic geometric relations and using reward signals derived from\nmathematical problem-solving tasks, our pipeline successfully captures the key\nfeatures of geometry problem-solving. This enables better task generalization\nand yields non-trivial improvements. Furthermore, even in out-of-distribution\nscenarios, the generated dataset enhances the general reasoning capabilities of\nmultimodal large language models, yielding accuracy improvements of\n$2.8\\%\\text{-}4.8\\%$ in statistics, arithmetic, algebraic, and numerical tasks\nwith non-geometric input images of MathVista and MathVerse, along with\n$2.4\\%\\text{-}3.9\\%$ improvements in Art, Design, Tech, and Engineering tasks\nin MMMU.","summary":"This paper introduces a Reinforcement Learning with Verifiable Rewards (RLVR) process to enhance data generation for geometric image captioning. The approach improves reasoning capabilities of multimodal large language models, yielding significant accuracy gains in various mathematical tasks.","authors":["Yue Xin","Wenyuan Wang","Rui Pan","Ruida Wang","Howard Meng","Renjie Pi","Shizhe Diao","Tong Zhang"],"categories":["cs.AI","cs.CV","cs.LG"],"affiliations":["University of Illinois Urbana-Champaign","Shanghai Jiao Tong University","Rutgers University","NVIDIA"],"keywords":["multimodal models","geometric reasoning","data synthesis","reinforcement learning","image-text pairs"],"language":"en","published_date":"2025-09-18T17:59:11Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15217v1"}
{"arxiv_id":"2509.15210v1","title":"Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR\n  Generation","abstract":"Realistic sound simulation plays a critical role in many applications. A key\nelement in sound simulation is the room impulse response (RIR), which\ncharacterizes how sound propagates from a source to a listener within a given\nspace. Recent studies have applied neural implicit methods to learn RIR using\ncontext information collected from the environment, such as scene images.\nHowever, these approaches do not effectively leverage explicit geometric\ninformation from the environment. To further exploit the potential of neural\nimplicit models with direct geometric features, we present Mesh-infused Neural\nAcoustic Field (MiNAF), which queries a rough room mesh at given locations and\nextracts distance distributions as an explicit representation of local context.\nOur approach demonstrates that incorporating explicit local geometric features\ncan better guide the neural network in generating more accurate RIR\npredictions. Through comparisons with conventional and state-of-the-art\nbaseline methods, we show that MiNAF performs competitively across various\nevaluation metrics. Furthermore, we verify the robustness of MiNAF in datasets\nwith limited training samples, demonstrating an advance in high-fidelity sound\nsimulation.","summary":"This paper presents Mesh-infused Neural Acoustic Field (MiNAF) for generating accurate Room Impulse Responses (RIR) by leveraging explicit geometric features. The approach enhances sound simulation fidelity and demonstrates robustness in limited training datasets.","authors":["Chen Si","Qianyi Wu","Chaitanya Amballa","Romit Roy Choudhury"],"categories":["cs.SD","cs.AI","cs.LG"],"affiliations":["University of California, San Diego","Monash University","University of Illinois, Urbana-Champaign"],"keywords":["Room Impulse Response","neural acoustic modeling","sound simulation","Mesh-infused Neural Acoustic Field","geometric features"],"language":"en","published_date":"2025-09-18T17:57:07Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15210v1"}
{"arxiv_id":"2509.15207v1","title":"FlowRL: Matching Reward Distributions for LLM Reasoning","abstract":"We propose FlowRL: matching the full reward distribution via flow balancing\ninstead of maximizing rewards in large language model (LLM) reinforcement\nlearning (RL). Recent advanced reasoning models adopt reward-maximizing methods\n(\\eg, PPO and GRPO), which tend to over-optimize dominant reward signals while\nneglecting less frequent but valid reasoning paths, thus reducing diversity. In\ncontrast, we transform scalar rewards into a normalized target distribution\nusing a learnable partition function, and then minimize the reverse KL\ndivergence between the policy and the target distribution. We implement this\nidea as a flow-balanced optimization method that promotes diverse exploration\nand generalizable reasoning trajectories. We conduct experiments on math and\ncode reasoning tasks: FlowRL achieves a significant average improvement of\n$10.0\\%$ over GRPO and $5.1\\%$ over PPO on math benchmarks, and performs\nconsistently better on code reasoning tasks. These results highlight reward\ndistribution-matching as a key step toward efficient exploration and diverse\nreasoning in LLM reinforcement learning.","summary":"FlowRL proposes a method for matching reward distributions in LLM reinforcement learning, promoting diverse exploration. It outperforms traditional reward-maximizing methods in math and code reasoning tasks.","authors":["Xuekai Zhu","Daixuan Cheng","Dinghuai Zhang","Hengli Li","Kaiyan Zhang","Che Jiang","Youbang Sun","Ermo Hua","Yuxin Zuo","Xingtai Lv","Qizheng Zhang","Lin Chen","Fanghao Shao","Bo Xue","Yunchong Song","Zhenjie Yang","Ganqu Cui","Ning Ding","Jianfeng Gao","Xiaodong Liu","Bowen Zhou","Hongyuan Mei","Zhouhan Lin"],"categories":["cs.LG","cs.AI","cs.CL"],"affiliations":["Shanghai Jiao Tong University","Shanghai AI Laboratory","Microsoft Research","Tsinghua University","Peking University","Renmin University of China","Stanford University","Toyota Technological Institute at Chicago"],"keywords":["FlowRL","reward distribution","reinforcement learning","diversity","LLM"],"language":"en","published_date":"2025-09-18T17:56:36Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15207v1"}
{"arxiv_id":"2509.15195v1","title":"Orion: Fuzzing Workflow Automation","abstract":"Fuzz testing is one of the most effective techniques for finding software\nvulnerabilities. While modern fuzzers can generate inputs and monitor\nexecutions automatically, the overall workflow, from analyzing a codebase, to\nconfiguring harnesses, to triaging results, still requires substantial manual\neffort. Prior attempts focused on single stages such as harness synthesis or\ninput minimization, leaving researchers to manually connect the pieces into a\ncomplete fuzzing campaign.\n  We introduce Orion, a framework that automates the the manual bottlenecks of\nfuzzing by integrating LLM reasoning with traditional tools, allowing campaigns\nto scale to settings where human effort alone was impractical. Orion uses LLMs\nfor code reasoning and semantic guidance, while relying on deterministic tools\nfor verification, iterative refinement, and tasks that require precision.\nAcross our benchmark suite, Orion reduces human effort by 46-204x depending on\nthe workflow stage, and we demonstrate its effectiveness through the discovery\nof two previously unknown vulnerabilities in the widely used open-source clib\nlibrary.","summary":"Orion is a framework that automates the manual bottlenecks of fuzzing by integrating LLM reasoning with traditional tools, significantly reducing human effort. It effectively scales fuzzing campaigns and has discovered previously unknown vulnerabilities in the clib library.","authors":["Max Bazalii","Marius Fleischer"],"categories":["cs.SE","cs.AI","cs.CR","D.4.6; I.2.2; D.2.5"],"affiliations":["NVIDIA"],"keywords":["Fuzzing","Workflow automation","Large language models","Security testing","Vulnerability discovery"],"language":"en","published_date":"2025-09-18T17:52:06Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15195v1"}
{"arxiv_id":"2509.15193v1","title":"TITAN: A Trajectory-Informed Technique for Adaptive Parameter Freezing\n  in Large-Scale VQE","abstract":"Variational quantum Eigensolver (VQE) is a leading candidate for harnessing\nquantum computers to advance quantum chemistry and materials simulations, yet\nits training efficiency deteriorates rapidly for large Hamiltonians. Two issues\nunderlie this bottleneck: (i) the no-cloning theorem imposes a linear growth in\ncircuit evaluations with the number of parameters per gradient step; and (ii)\ndeeper circuits encounter barren plateaus (BPs), leading to exponentially\nincreasing measurement overheads. To address these challenges, here we propose\na deep learning framework, dubbed Titan, which identifies and freezes inactive\nparameters of a given ansatze at initialization for a specific class of\nHamiltonians, reducing the optimization overhead without sacrificing accuracy.\nThe motivation of Titan starts with our empirical findings that a subset of\nparameters consistently has a negligible influence on training dynamics. Its\ndesign combines a theoretically grounded data construction strategy, ensuring\neach training example is informative and BP-resilient, with an adaptive neural\narchitecture that generalizes across ansatze of varying sizes. Across benchmark\ntransverse-field Ising models, Heisenberg models, and multiple molecule systems\nup to 30 qubits, Titan achieves up to 3 times faster convergence and 40% to 60%\nfewer circuit evaluations than state-of-the-art baselines, while matching or\nsurpassing their estimation accuracy. By proactively trimming parameter space,\nTitan lowers hardware demands and offers a scalable path toward utilizing VQE\nto advance practical quantum chemistry and materials science.","summary":"The TITAN framework improves the efficiency of the Variational Quantum Eigensolver by freezing inactive parameters, reducing optimization overhead while maintaining accuracy. It achieves faster convergence and fewer circuit evaluations across various quantum models.","authors":["Yifeng Peng","Xinyi Li","Samuel Yen-Chi Chen","Kaining Zhang","Zhiding Liang","Ying Wang","Yuxuan Du"],"categories":["quant-ph","cs.AI"],"affiliations":["Stevens Institute of Technology","Wells Fargo","Nanyang Technological University","Rensselaer Polytechnic Institute"],"keywords":["Variational Quantum Eigensolver","Quantum Computing","Parameter Optimization","Deep Learning","Adaptive Techniques"],"language":"en","published_date":"2025-09-18T17:50:02Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15193v1"}
{"arxiv_id":"2509.15188v1","title":"Fast and Fluent Diffusion Language Models via Convolutional Decoding and\n  Rejective Fine-tuning","abstract":"Autoregressive (AR) language models generate text one token at a time, which\nlimits their inference speed. Diffusion-based language models offer a promising\nalternative, as they can decode multiple tokens in parallel. However, we\nidentify a key bottleneck in current diffusion LMs: the long decoding-window\nproblem, where tokens generated far from the input context often become\nirrelevant or repetitive. Previous solutions like semi-autoregressive address\nthis issue by splitting windows into blocks, but this sacrifices speed and\nbidirectionality, eliminating the main advantage of diffusion models. To\novercome this, we propose Convolutional decoding (Conv), a normalization-based\nmethod that narrows the decoding window without hard segmentation, leading to\nbetter fluency and flexibility. Additionally, we introduce Rejecting Rule-based\nFine-Tuning (R2FT), a post-hoc training scheme that better aligns tokens at\npositions far from context. Our methods achieve state-of-the-art results on\nopen-ended generation benchmarks (e.g., AlpacaEval) among diffusion LM\nbaselines, with significantly lower step size than previous works,\ndemonstrating both speed and quality improvements.","summary":"This paper proposes Convolutional decoding and Rejecting Rule-based Fine-Tuning to enhance the performance of diffusion language models. The methods address the long decoding-window problem, achieving state-of-the-art results in text generation.","authors":["Yeongbin Seo","Dongha Lee","Jaehyung Kim","Jinyoung Yeo"],"categories":["cs.CL","cs.AI","cs.LG","68T50","I.2.7"],"affiliations":["Yonsei University"],"keywords":["Diffusion Models","Language Models","Convolutional Decoding","Fine-Tuning","Text Generation"],"language":"en","published_date":"2025-09-18T17:48:21Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15188v1"}
{"arxiv_id":"2509.15174v1","title":"SMARTER: A Data-efficient Framework to Improve Toxicity Detection with\n  Explanation via Self-augmenting Large Language Models","abstract":"WARNING: This paper contains examples of offensive materials. Toxic content\nhas become pervasive on social media platforms. We introduce SMARTER, a\ndata-efficient two-stage framework for explainable content moderation using\nLarge Language Models (LLMs). In Stage 1, we leverage LLMs' own outputs to\ngenerate synthetic explanations for both correct and incorrect labels, enabling\nalignment via preference optimization with minimal human supervision. In Stage\n2, we refine explanation quality through cross-model training, allowing weaker\nmodels to align stylistically and semantically with stronger ones. Experiments\non three benchmark tasks -- HateXplain, Latent Hate, and Implicit Hate --\ndemonstrate that SMARTER enables LLMs to achieve up to a 13.5% macro-F1\nimprovement over standard few-shot baselines while using only a fraction of the\nfull training data. Our framework offers a scalable strategy for low-resource\nsettings by harnessing LLMs' self-improving capabilities for both\nclassification and explanation.","summary":"The paper introduces SMARTER, a data-efficient framework for explainable content moderation using Large Language Models. It demonstrates significant improvements in toxicity detection with minimal human supervision.","authors":["Huy Nghiem","Advik Sachdeva","Hal Daumé III"],"categories":["cs.CL","cs.AI"],"affiliations":["University of Maryland"],"keywords":["toxicity detection","content moderation","large language models","explainable AI","data-efficient framework"],"language":"en","published_date":"2025-09-18T17:30:36Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15174v1"}
{"arxiv_id":"2509.15172v1","title":"Internalizing Self-Consistency in Language Models: Multi-Agent Consensus\n  Alignment","abstract":"Language Models (LMs) are inconsistent reasoners, often generating\ncontradictory responses to identical prompts. While inference-time methods can\nmitigate these inconsistencies, they fail to address the core problem: LMs\nstruggle to reliably select reasoning pathways leading to consistent outcomes\nunder exploratory sampling. To address this, we formalize self-consistency as\nan intrinsic property of well-aligned reasoning models and introduce\nMulti-Agent Consensus Alignment (MACA), a reinforcement learning framework that\npost-trains models to favor reasoning trajectories aligned with their internal\nconsensus using majority\/minority outcomes from multi-agent debate. These\ntrajectories emerge from deliberative exchanges where agents ground reasoning\nin peer arguments, not just aggregation of independent attempts, creating\nricher consensus signals than single-round majority voting. MACA enables agents\nto teach themselves to be more decisive and concise, and better leverage peer\ninsights in multi-agent settings without external supervision, driving\nsubstantial improvements across self-consistency (+27.6% on GSM8K),\nsingle-agent reasoning (+23.7% on MATH), sampling-based inference (+22.4%\nPass@20 on MATH), and multi-agent ensemble decision-making (+42.7% on MathQA).\nThese findings, coupled with strong generalization to unseen benchmarks (+16.3%\non GPQA, +11.6% on CommonsenseQA), demonstrate robust self-alignment that more\nreliably unlocks latent reasoning potential of language models.","summary":"This paper introduces Multi-Agent Consensus Alignment (MACA), a framework that enhances self-consistency in language models through collaborative reasoning. The approach significantly improves decision-making and reasoning quality across various benchmarks.","authors":["Ankur Samanta","Akshayaa Magesh","Youliang Yu","Runzhe Wu","Ayush Jain","Daniel Jiang","Boris Vidolov","Paul Sajda","Yonathan Efroni","Kaveh Hassani"],"categories":["cs.AI"],"affiliations":["Meta AI","Meta Superintelligence Labs","Columbia University"],"keywords":["self-consistency","language models","reinforcement learning","multi-agent","consensus"],"language":"en","published_date":"2025-09-18T17:27:28Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15172v1"}
{"arxiv_id":"2509.15170v1","title":"Watermarking and Anomaly Detection in Machine Learning Models for LORA\n  RF Fingerprinting","abstract":"Radio frequency fingerprint identification (RFFI) distinguishes wireless\ndevices by the small variations in their analog circuits, avoiding heavy\ncryptographic authentication. While deep learning on spectrograms improves\naccuracy, models remain vulnerable to copying, tampering, and evasion. We\npresent a stronger RFFI system combining watermarking for ownership proof and\nanomaly detection for spotting suspicious inputs. Using a ResNet-34 on log-Mel\nspectrograms, we embed three watermarks: a simple trigger, an adversarially\ntrained trigger robust to noise and filtering, and a hidden gradient\/weight\nsignature. A convolutional Variational Autoencoders (VAE) with Kullback-Leibler\n(KL) warm-up and free-bits flags off-distribution queries. On the LoRa dataset,\nour system achieves 94.6% accuracy, 98% watermark success, and 0.94 AUROC,\noffering verifiable, tamper-resistant authentication.","summary":"This work presents a robust radio frequency fingerprint identification system that integrates watermarking and anomaly detection to enhance security against adversarial threats. The proposed method achieves high accuracy and watermark success rates on the LoRa dataset.","authors":["Aarushi Mahajan","Wayne Burleson"],"categories":["cs.CR","cs.AI","eess.SP"],"affiliations":["University of Massachusetts Amherst"],"keywords":["Anomaly detection","Autoencoders","Deep learning","Model watermarking","Radio frequency fingerprint identification"],"language":"en","published_date":"2025-09-18T17:21:33Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15170v1"}
{"arxiv_id":"2509.15167v1","title":"Semi-Supervised 3D Medical Segmentation from 2D Natural Images\n  Pretrained Model","abstract":"This paper explores the transfer of knowledge from general vision models\npretrained on 2D natural images to improve 3D medical image segmentation. We\nfocus on the semi-supervised setting, where only a few labeled 3D medical\nimages are available, along with a large set of unlabeled images. To tackle\nthis, we propose a model-agnostic framework that progressively distills\nknowledge from a 2D pretrained model to a 3D segmentation model trained from\nscratch. Our approach, M&N, involves iterative co-training of the two models\nusing pseudo-masks generated by each other, along with our proposed learning\nrate guided sampling that adaptively adjusts the proportion of labeled and\nunlabeled data in each training batch to align with the models' prediction\naccuracy and stability, minimizing the adverse effect caused by inaccurate\npseudo-masks. Extensive experiments on multiple publicly available datasets\ndemonstrate that M&N achieves state-of-the-art performance, outperforming\nthirteen existing semi-supervised segmentation approaches under all different\nsettings. Importantly, ablation studies show that M&N remains model-agnostic,\nallowing seamless integration with different architectures. This ensures its\nadaptability as more advanced models emerge. The code is available at\nhttps:\/\/github.com\/pakheiyeung\/M-N.","summary":"This paper presents a model-agnostic framework for improving 3D medical image segmentation using knowledge from 2D pretrained models in a semi-supervised setting. The proposed method, M&N, demonstrates state-of-the-art performance across various datasets.","authors":["Pak-Hei Yeung","Jayroop Ramesh","Pengfei Lyu","Ana Namburete","Jagath Rajapakse"],"categories":["cs.CV","cs.AI","cs.LG"],"affiliations":["Nanyang Technological University","University of Oxford","Northeastern University"],"keywords":["Knowledge Distillation","Semi-Supervised Segmentation","Domain Adaptation"],"language":"en","published_date":"2025-09-18T17:17:52Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15167v1"}
{"arxiv_id":"2509.15156v1","title":"Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for\n  Vision Models","abstract":"Contemporary deep learning models have achieved impressive performance in\nimage classification by primarily leveraging statistical regularities within\nlarge datasets, but they rarely incorporate structured insights drawn directly\nfrom perceptual psychology. To explore the potential of perceptually motivated\ninductive biases, we propose integrating classic geometric visual illusions\nwell-studied phenomena from human perception into standard image-classification\ntraining pipelines. Specifically, we introduce a synthetic, parametric\ngeometric-illusion dataset and evaluate three multi-source learning strategies\nthat combine illusion recognition tasks with ImageNet classification\nobjectives. Our experiments reveal two key conceptual insights: (i)\nincorporating geometric illusions as auxiliary supervision systematically\nimproves generalization, especially in visually challenging cases involving\nintricate contours and fine textures; and (ii) perceptually driven inductive\nbiases, even when derived from synthetic stimuli traditionally considered\nunrelated to natural image recognition, can enhance the structural sensitivity\nof both CNN and transformer-based architectures. These results demonstrate a\nnovel integration of perceptual science and machine learning and suggest new\ndirections for embedding perceptual priors into vision model design.","summary":"This study explores the integration of geometric visual illusions into image classification models to enhance generalization and structural sensitivity. The findings suggest that perceptual insights can improve deep learning performance in challenging visual tasks.","authors":["Haobo Yang","Minghao Guo","Dequan Yang","Wenyu Wang"],"categories":["cs.CV","cs.AI"],"affiliations":["Mohamed bin Zayed University of Artificial Intelligence","University of Oxford"],"keywords":["geometric visual illusions","inductive biases","image classification","perceptual psychology","machine learning"],"language":"en","published_date":"2025-09-18T17:00:42Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15156v1"}
{"arxiv_id":"2509.15151v1","title":"Exploring How Audio Effects Alter Emotion with Foundation Models","abstract":"Audio effects (FX) such as reverberation, distortion, modulation, and dynamic\nrange processing play a pivotal role in shaping emotional responses during\nmusic listening. While prior studies have examined links between low-level\naudio features and affective perception, the systematic impact of audio FX on\nemotion remains underexplored. This work investigates how foundation models -\nlarge-scale neural architectures pretrained on multimodal data - can be\nleveraged to analyze these effects. Such models encode rich associations\nbetween musical structure, timbre, and affective meaning, offering a powerful\nframework for probing the emotional consequences of sound design techniques. By\napplying various probing methods to embeddings from deep learning models, we\nexamine the complex, nonlinear relationships between audio FX and estimated\nemotion, uncovering patterns tied to specific effects and evaluating the\nrobustness of foundation audio models. Our findings aim to advance\nunderstanding of the perceptual impact of audio production practices, with\nimplications for music cognition, performance, and affective computing.","summary":"This work investigates how audio effects influence emotional responses in music using foundation models. It aims to uncover the complex relationships between audio FX and emotion, enhancing understanding of sound design's perceptual impact.","authors":["Stelios Katsis","Vassilis Lyberatos","Spyridon Kantarelis","Edmund Dervakos","Giorgos Stamou"],"categories":["cs.SD","cs.AI"],"affiliations":["National Technical University of Athens"],"keywords":["Audio Effects","Emotion","Foundation Models","Affective Computing","Music Cognition"],"language":"en","published_date":"2025-09-18T16:57:08Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15151v1"}
{"arxiv_id":"2509.15130v1","title":"WorldForge: Unlocking Emergent 3D\/4D Generation in Video Diffusion Model\n  via Training-Free Guidance","abstract":"Recent video diffusion models demonstrate strong potential in spatial\nintelligence tasks due to their rich latent world priors. However, this\npotential is hindered by their limited controllability and geometric\ninconsistency, creating a gap between their strong priors and their practical\nuse in 3D\/4D tasks. As a result, current approaches often rely on retraining or\nfine-tuning, which risks degrading pretrained knowledge and incurs high\ncomputational costs. To address this, we propose WorldForge, a training-free,\ninference-time framework composed of three tightly coupled modules. Intra-Step\nRecursive Refinement introduces a recursive refinement mechanism during\ninference, which repeatedly optimizes network predictions within each denoising\nstep to enable precise trajectory injection. Flow-Gated Latent Fusion leverages\noptical flow similarity to decouple motion from appearance in the latent space\nand selectively inject trajectory guidance into motion-related channels.\nDual-Path Self-Corrective Guidance compares guided and unguided denoising paths\nto adaptively correct trajectory drift caused by noisy or misaligned structural\nsignals. Together, these components inject fine-grained, trajectory-aligned\nguidance without training, achieving both accurate motion control and\nphotorealistic content generation. Extensive experiments across diverse\nbenchmarks validate our method's superiority in realism, trajectory\nconsistency, and visual fidelity. This work introduces a novel plug-and-play\nparadigm for controllable video synthesis, offering a new perspective on\nleveraging generative priors for spatial intelligence.","summary":"WorldForge is a training-free framework that utilizes a pre-trained video diffusion model for 3D and 4D tasks. It enables precise camera control and high-quality outputs in scene generation and re-rendering.","authors":["Chenxi Song","Yanming Yang","Tong Zhao","Ruibo Li","Chi Zhang"],"categories":["cs.GR","cs.AI","cs.CV"],"affiliations":["Westlake University","Nanyang Technological University"],"keywords":["3D generation","4D generation","video diffusion","training-free","scene re-rendering"],"language":"en","published_date":"2025-09-18T16:40:47Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15130v1"}
{"arxiv_id":"2509.15116v1","title":"The mechanization of science illustrated by the Lean formalization of\n  the multi-graded Proj construction","abstract":"We formalize the multi-graded Proj construction in Lean4, illustrating\nmechanized mathematics and formalization.","summary":"The paper discusses the mechanization of scientific reasoning and the potential of machines to assist in algebra checking and theorem proving. It explores the implications of using machines for creative problem-solving in mathematics.","authors":["Arnaud Mayeux","Jujian Zhang"],"categories":["cs.LO","cs.AI","math.AG"],"affiliations":["Einstein Institute of Mathematics, The Hebrew University of Jerusalem","Imperial College London"],"keywords":["mechanization","theorem proving","algebra checking","heuristics","scientific reasoning"],"language":"en","published_date":"2025-09-18T16:19:41Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15116v1"}
{"arxiv_id":"2509.15103v1","title":"Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement\n  Learning","abstract":"Partial agent failure becomes inevitable when systems scale up, making it\ncrucial to identify the subset of agents whose compromise would most severely\ndegrade overall performance. In this paper, we study this Vulnerable Agent\nIdentification (VAI) problem in large-scale multi-agent reinforcement learning\n(MARL). We frame VAI as a Hierarchical Adversarial Decentralized Mean Field\nControl (HAD-MFC), where the upper level involves an NP-hard combinatorial task\nof selecting the most vulnerable agents, and the lower level learns worst-case\nadversarial policies for these agents using mean-field MARL. The two problems\nare coupled together, making HAD-MFC difficult to solve. To solve this, we\nfirst decouple the hierarchical process by Fenchel-Rockafellar transform,\nresulting a regularized mean-field Bellman operator for upper level that\nenables independent learning at each level, thus reducing computational\ncomplexity. We then reformulate the upper-level combinatorial problem as a MDP\nwith dense rewards from our regularized mean-field Bellman operator, enabling\nus to sequentially identify the most vulnerable agents by greedy and RL\nalgorithms. This decomposition provably preserves the optimal solution of the\noriginal HAD-MFC. Experiments show our method effectively identifies more\nvulnerable agents in large-scale MARL and the rule-based system, fooling system\ninto worse failures, and learns a value function that reveals the vulnerability\nof each agent.","summary":"This paper addresses the identification of vulnerable agents in large-scale multi-agent reinforcement learning environments. The authors propose methods to enhance the robustness of agent interactions.","authors":["Simin Li","Zheng Yuwei","Zihao Mao","Linhao Wang","Ruixiao Xu","Chengdong Ma","Xin Yu","Yuqing Ma","Qi Dou","Xin Wang","Jie Luo","Bo An","Yaodong Yang","Weifeng Lv","Xianglong Liu"],"categories":["cs.MA","cs.AI"],"affiliations":["Beihang University","Peking University","Chinese Academy of Sciences","The Chinese University of Hong Kong","Nanyang Technological University"],"keywords":["Multi-Agent","Reinforcement Learning","Vulnerable Agent","Identification","Artificial Intelligence"],"language":"en","published_date":"2025-09-18T16:03:50Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15103v1"}
{"arxiv_id":"2509.15098v1","title":"TextMine: LLM-Powered Knowledge Extraction for Humanitarian Mine Action","abstract":"Humanitarian Mine Action has generated extensive best-practice knowledge, but\nmuch remains locked in unstructured reports. We introduce TextMine, an\nontology-guided pipeline that uses Large Language Models to extract knowledge\ntriples from HMA texts. TextMine integrates document chunking, domain-aware\nprompting, triple extraction, and both reference-based and LLM-as-a-Judge\nevaluation. We also create the first HMA ontology and a curated dataset of\nreal-world demining reports. Experiments show ontology-aligned prompts boost\nextraction accuracy by 44.2%, cut hallucinations by 22.5%, and improve format\nconformance by 20.9% over baselines. While validated on Cambodian reports,\nTextMine can adapt to global demining efforts or other domains, transforming\nunstructured data into structured knowledge.","summary":"TextMine is an ontology-guided pipeline that utilizes Large Language Models to extract structured knowledge from unstructured humanitarian mine action reports. It significantly improves extraction accuracy and can adapt to various domains.","authors":["Chenyue Zhou","Gürkan Solmaz","Flavio Cirillo","Kiril Gashteovski","Jonathan Fürst"],"categories":["cs.CL","cs.AI"],"affiliations":["NEC Laboratories Europe","University of Stuttgart","Zurich University of Applied Sciences","Ss. Cyril and Methodius University of Skopje"],"keywords":["Humanitarian Mine Action","Knowledge Extraction","Large Language Models","Ontology","Knowledge Graph"],"language":"en","published_date":"2025-09-18T15:55:19Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15098v1"}
{"arxiv_id":"2509.15095v1","title":"Listening, Imagining \\& Refining: A Heuristic Optimized ASR Correction\n  Framework with LLMs","abstract":"Automatic Speech Recognition (ASR) systems remain prone to errors that affect\ndownstream applications. In this paper, we propose LIR-ASR, a heuristic\noptimized iterative correction framework using LLMs, inspired by human auditory\nperception. LIR-ASR applies a \"Listening-Imagining-Refining\" strategy,\ngenerating phonetic variants and refining them in context. A heuristic\noptimization with finite state machine (FSM) is introduced to prevent the\ncorrection process from being trapped in local optima and rule-based\nconstraints help maintain semantic fidelity. Experiments on both English and\nChinese ASR outputs show that LIR-ASR achieves average reductions in CER\/WER of\nup to 1.5 percentage points compared to baselines, demonstrating substantial\naccuracy gains in transcription.","summary":"The paper proposes LIR-ASR, a heuristic optimized framework for ASR correction using large language models, inspired by human auditory perception. It demonstrates significant accuracy improvements in transcription for both English and Chinese ASR outputs.","authors":["Yutong Liu","Ziyue Zhang","Yongbin Yu","Xiangxiang Wang","Yuqing Cai","Nyima Tashi"],"categories":["eess.AS","cs.AI"],"affiliations":["University of Electronic Science and Technology of China","Tibet University"],"keywords":["ASR correction","large language model","heuristic optimization","transcription accuracy","iterative refinement"],"language":"en","published_date":"2025-09-18T15:50:54Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15095v1"}
{"arxiv_id":"2509.15084v1","title":"From Sea to System: Exploring User-Centered Explainable AI for Maritime\n  Decision Support","abstract":"As autonomous technologies increasingly shape maritime operations,\nunderstanding why an AI system makes a decision becomes as crucial as what it\ndecides. In complex and dynamic maritime environments, trust in AI depends not\nonly on performance but also on transparency and interpretability. This paper\nhighlights the importance of Explainable AI (XAI) as a foundation for effective\nhuman-machine teaming in the maritime domain, where informed oversight and\nshared understanding are essential. To support the user-centered integration of\nXAI, we propose a domain-specific survey designed to capture maritime\nprofessionals' perceptions of trust, usability, and explainability. Our aim is\nto foster awareness and guide the development of user-centric XAI systems\ntailored to the needs of seafarers and maritime teams.","summary":"This paper emphasizes the significance of Explainable AI in maritime operations, focusing on user-centered integration to enhance trust and usability. It proposes a survey to capture maritime professionals' perceptions of AI decision-making.","authors":["Doreen Jirak","Pieter Maes","Armeen Saroukanoff","Dirk van Rooy"],"categories":["cs.AI","cs.CY","cs.HC"],"affiliations":["University of Antwerp","Antwerp Maritime Academy"],"keywords":["Human-AI Decision-Making","Explainable AI","Trust","User-Centered Design","Maritime Operations"],"language":"en","published_date":"2025-09-18T15:42:54Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15084v1"}
{"arxiv_id":"2509.15058v1","title":"Communication Efficient Split Learning of ViTs with Attention-based\n  Double Compression","abstract":"This paper proposes a novel communication-efficient Split Learning (SL)\nframework, named Attention-based Double Compression (ADC), which reduces the\ncommunication overhead required for transmitting intermediate Vision\nTransformers activations during the SL training process. ADC incorporates two\nparallel compression strategies. The first one merges samples' activations that\nare similar, based on the average attention score calculated in the last client\nlayer; this strategy is class-agnostic, meaning that it can also merge samples\nhaving different classes, without losing generalization ability nor decreasing\nfinal results. The second strategy follows the first and discards the least\nmeaningful tokens, further reducing the communication cost. Combining these\nstrategies not only allows for sending less during the forward pass, but also\nthe gradients are naturally compressed, allowing the whole model to be trained\nwithout additional tuning or approximations of the gradients. Simulation\nresults demonstrate that Attention-based Double Compression outperforms\nstate-of-the-art SL frameworks by significantly reducing communication\noverheads while maintaining high accuracy.","summary":"This paper presents a novel framework called Attention-based Double Compression (ADC) for communication-efficient Split Learning, which reduces overhead during training of Vision Transformers. The proposed method combines two compression strategies to enhance performance while maintaining accuracy.","authors":["Federico Alvetreti","Jary Pomponi","Paolo Di Lorenzo","Simone Scardapane"],"categories":["cs.LG","cs.AI","cs.CV","stat.ML"],"affiliations":["Sapienza University of Rome","Consorzio Nazionale Interuniversitario per le Telecomunicazioni"],"keywords":["Split Learning","Vision Transformers","communication efficiency","compression strategies","deep neural networks"],"language":"en","published_date":"2025-09-18T15:22:24Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15058v1"}
{"arxiv_id":"2509.15057v1","title":"Balancing Sparse RNNs with Hyperparameterization Benefiting\n  Meta-Learning","abstract":"This paper develops alternative hyperparameters for specifying sparse\nRecurrent Neural Networks (RNNs). These hyperparameters allow for varying\nsparsity within the trainable weight matrices of the model while improving\noverall performance. This architecture enables the definition of a novel\nmetric, hidden proportion, which seeks to balance the distribution of unknowns\nwithin the model and provides significant explanatory power of model\nperformance. Together, the use of the varied sparsity RNN architecture combined\nwith the hidden proportion metric generates significant performance gains while\nimproving performance expectations on an a priori basis. This combined approach\nprovides a path forward towards generalized meta-learning applications and\nmodel optimization based on intrinsic characteristics of the data set,\nincluding input and output dimensions.","summary":"This paper develops novel hyperparameters for sparse Recurrent Neural Networks (RNNs) that improve performance and enable a new metric for balancing unknowns. The approach enhances model optimization and supports generalized meta-learning applications.","authors":["Quincy Hershey","Randy Paffenroth"],"categories":["cs.LG","cs.AI"],"affiliations":["Worcester Polytechnic Institute"],"keywords":["RNN","sparsity","meta-learning","hyperparameters","model optimization"],"language":"en","published_date":"2025-09-18T15:20:13Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15057v1"}
{"arxiv_id":"2509.15044v1","title":"Credit Card Fraud Detection","abstract":"Credit card fraud remains a significant challenge due to class imbalance and\nfraudsters mimicking legitimate behavior. This study evaluates five machine\nlearning models - Logistic Regression, Random Forest, XGBoost, K-Nearest\nNeighbors (KNN), and Multi-Layer Perceptron (MLP) on a real-world dataset using\nundersampling, SMOTE, and a hybrid approach. Our models are evaluated on the\noriginal imbalanced test set to better reflect real-world performance. Results\nshow that the hybrid method achieves the best balance between recall and\nprecision, especially improving MLP and KNN performance.","summary":"This study evaluates five machine learning models for credit card fraud detection, focusing on class imbalance and resampling strategies. Results indicate that a hybrid method improves model performance, particularly for MLP and KNN.","authors":["Iva Popova","Hamza A. A. Gardi"],"categories":["cs.LG","cs.AI"],"affiliations":["ETIT-KIT","IIIT"],"keywords":["credit card fraud","machine learning","class imbalance","resampling techniques","fraud detection"],"language":"en","published_date":"2025-09-18T15:08:14Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15044v1"}
{"arxiv_id":"2509.15042v1","title":"Reinforcement Learning Agent for a 2D Shooter Game","abstract":"Reinforcement learning agents in complex game environments often suffer from\nsparse rewards, training instability, and poor sample efficiency. This paper\npresents a hybrid training approach that combines offline imitation learning\nwith online reinforcement learning for a 2D shooter game agent. We implement a\nmulti-head neural network with separate outputs for behavioral cloning and\nQ-learning, unified by shared feature extraction layers with attention\nmechanisms. Initial experiments using pure deep Q-Networks exhibited\nsignificant instability, with agents frequently reverting to poor policies\ndespite occasional good performance. To address this, we developed a hybrid\nmethodology that begins with behavioral cloning on demonstration data from\nrule-based agents, then transitions to reinforcement learning. Our hybrid\napproach achieves consistently above 70% win rate against rule-based opponents,\nsubstantially outperforming pure reinforcement learning methods which showed\nhigh variance and frequent performance degradation. The multi-head architecture\nenables effective knowledge transfer between learning modes while maintaining\ntraining stability. Results demonstrate that combining demonstration-based\ninitialization with reinforcement learning optimization provides a robust\nsolution for developing game AI agents in complex multi-agent environments\nwhere pure exploration proves insufficient.","summary":"This paper presents a hybrid training approach combining offline imitation learning with online reinforcement learning for a 2D shooter game agent. The methodology achieves a win rate above 70% against rule-based opponents, outperforming traditional reinforcement learning methods.","authors":["Thomas Ackermann","Moritz Spang","Hamza A. A. Gardi"],"categories":["cs.LG","cs.AI"],"affiliations":["Karlsruhe Institute of Technology"],"keywords":["reinforcement learning","game agent","video games","shooter game","hybrid training"],"language":"en","published_date":"2025-09-18T15:07:41Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15042v1"}
{"arxiv_id":"2509.15040v1","title":"From Patterns to Predictions: A Shapelet-Based Framework for Directional\n  Forecasting in Noisy Financial Markets","abstract":"Directional forecasting in financial markets requires both accuracy and\ninterpretability. Before the advent of deep learning, interpretable approaches\nbased on human-defined patterns were prevalent, but their structural vagueness\nand scale ambiguity hindered generalization. In contrast, deep learning models\ncan effectively capture complex dynamics, yet often offer limited transparency.\nTo bridge this gap, we propose a two-stage framework that integrates\nunsupervised pattern extracion with interpretable forecasting. (i) SIMPC\nsegments and clusters multivariate time series, extracting recurrent patterns\nthat are invariant to amplitude scaling and temporal distortion, even under\nvarying window sizes. (ii) JISC-Net is a shapelet-based classifier that uses\nthe initial part of extracted patterns as input and forecasts subsequent\npartial sequences for short-term directional movement. Experiments on Bitcoin\nand three S&P 500 equities demonstrate that our method ranks first or second in\n11 out of 12 metric--dataset combinations, consistently outperforming\nbaselines. Unlike conventional deep learning models that output buy-or-sell\nsignals without interpretable justification, our approach enables transparent\ndecision-making by revealing the underlying pattern structures that drive\npredictive outcomes.","summary":"This paper presents a two-stage framework for directional forecasting in financial markets that combines unsupervised pattern extraction with interpretable forecasting. The proposed method outperforms traditional models by providing transparent decision-making through the analysis of underlying pattern structures.","authors":["Juwon Kim","Hyunwook Lee","Hyotaek Jeon","Seungmin Jin","Sungahn Ko"],"categories":["cs.LG","cs.AI"],"affiliations":["Pohang University of Science and Technology","Ulsan National Institute of Science and Technology"],"keywords":["Financial Forecasting","Multivariate Time Series","Pattern Extraction","Unsupervised Learning","Explainable ML"],"language":"en","published_date":"2025-09-18T15:05:27Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15040v1"}
{"arxiv_id":"2509.15035v1","title":"Calibrated Generative AI as Meta-Reviewer: A Systemic Functional\n  Linguistics Discourse Analysis of Reviews of Peer Reviews","abstract":"This study investigates the use of generative AI to support formative\nassessment through machine generated reviews of peer reviews in graduate online\ncourses in a public university in the United States. Drawing on Systemic\nFunctional Linguistics and Appraisal Theory, we analyzed 120 metareviews to\nexplore how generative AI feedback constructs meaning across ideational,\ninterpersonal, and textual dimensions. The findings suggest that generative AI\ncan approximate key rhetorical and relational features of effective human\nfeedback, offering directive clarity while also maintaining a supportive\nstance. The reviews analyzed demonstrated a balance of praise and constructive\ncritique, alignment with rubric expectations, and structured staging that\nforegrounded student agency. By modeling these qualities, AI metafeedback has\nthe potential to scaffold feedback literacy and enhance leaner engagement with\npeer review.","summary":"This study analyzes peer reviews using a calibrated generative AI as a meta-reviewer. It employs systemic functional linguistics to understand the discourse in the reviews.","authors":["Gabriela C. Zapata","Bill Cope","Mary Kalantzis","Duane Searsmith"],"categories":["cs.AI","cs.HC"],"affiliations":["University of Nottingham","University of Illinois"],"keywords":["Generative AI","Meta-Reviewer","Discourse Analysis","Peer Reviews","Systemic Functional Linguistics"],"language":"en","published_date":"2025-09-18T15:00:44Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15035v1"}
{"arxiv_id":"2509.15032v1","title":"Sample Efficient Experience Replay in Non-stationary Environments","abstract":"Reinforcement learning (RL) in non-stationary environments is challenging, as\nchanging dynamics and rewards quickly make past experiences outdated.\nTraditional experience replay (ER) methods, especially those using TD-error\nprioritization, struggle to distinguish between changes caused by the agent's\npolicy and those from the environment, resulting in inefficient learning under\ndynamic conditions. To address this challenge, we propose the Discrepancy of\nEnvironment Dynamics (DoE), a metric that isolates the effects of environment\nshifts on value functions. Building on this, we introduce Discrepancy of\nEnvironment Prioritized Experience Replay (DEER), an adaptive ER framework that\nprioritizes transitions based on both policy updates and environmental changes.\nDEER uses a binary classifier to detect environment changes and applies\ndistinct prioritization strategies before and after each shift, enabling more\nsample-efficient learning. Experiments on four non-stationary benchmarks\ndemonstrate that DEER further improves the performance of off-policy algorithms\nby 11.54 percent compared to the best-performing state-of-the-art ER methods.","summary":"This paper introduces the Discrepancy of Environment Dynamics (DoE) metric and the DEER framework to improve experience replay in non-stationary environments. Experiments show DEER enhances off-policy algorithm performance by 11.54% over existing methods.","authors":["Tianyang Duan","Zongyuan Zhang","Songxiao Guo","Yuanye Zhao","Zheng Lin","Zihan Fang","Yi Liu","Dianxin Luan","Dong Huang","Heming Cui","Yong Cui"],"categories":["cs.LG","cs.AI","cs.NI"],"affiliations":["The University of Hong Kong","Hebei University of Economics and Business","City University of Hong Kong","University of Edinburgh","National University of Singapore","Tsinghua University"],"keywords":["Reinforcement Learning","Non-stationary Environment","Experience Replay","Off-policy Algorithm","Sample Efficiency"],"language":"en","published_date":"2025-09-18T14:57:09Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15032v1"}
{"arxiv_id":"2509.15027v1","title":"CLEAR: A Comprehensive Linguistic Evaluation of Argument Rewriting by\n  Large Language Models","abstract":"While LLMs have been extensively studied on general text generation tasks,\nthere is less research on text rewriting, a task related to general text\ngeneration, and particularly on the behavior of models on this task. In this\npaper we analyze what changes LLMs make in a text rewriting setting. We focus\nspecifically on argumentative texts and their improvement, a task named\nArgument Improvement (ArgImp). We present CLEAR: an evaluation pipeline\nconsisting of 57 metrics mapped to four linguistic levels: lexical, syntactic,\nsemantic and pragmatic. This pipeline is used to examine the qualities of\nLLM-rewritten arguments on a broad set of argumentation corpora and compare the\nbehavior of different LLMs on this task and analyze the behavior of different\nLLMs on this task in terms of linguistic levels. By taking all four linguistic\nlevels into consideration, we find that the models perform ArgImp by shortening\nthe texts while simultaneously increasing average word length and merging\nsentences. Overall we note an increase in the persuasion and coherence\ndimensions.","summary":"This paper analyzes the changes made by large language models in text rewriting, focusing on argumentative texts. It presents CLEAR, an evaluation pipeline to assess the quality of LLM-rewritten arguments across various linguistic levels.","authors":["Thomas Huber","Christina Niklaus"],"categories":["cs.CL","cs.AI"],"affiliations":["University of St. Gallen"],"keywords":["Large Language Models","text rewriting","argument improvement","linguistic evaluation","natural language processing"],"language":"en","published_date":"2025-09-18T14:53:41Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15027v1"}
{"arxiv_id":"2509.15024v1","title":"Attention Beyond Neighborhoods: Reviving Transformer for Graph\n  Clustering","abstract":"Attention mechanisms have become a cornerstone in modern neural networks,\ndriving breakthroughs across diverse domains. However, their application to\ngraph structured data, where capturing topological connections is essential,\nremains underexplored and underperforming compared to Graph Neural Networks\n(GNNs), particularly in the graph clustering task. GNN tends to overemphasize\nneighborhood aggregation, leading to a homogenization of node representations.\nConversely, Transformer tends to over globalize, highlighting distant nodes at\nthe expense of meaningful local patterns. This dichotomy raises a key question:\nIs attention inherently redundant for unsupervised graph learning? To address\nthis, we conduct a comprehensive empirical analysis, uncovering the\ncomplementary weaknesses of GNN and Transformer in graph clustering. Motivated\nby these insights, we propose the Attentive Graph Clustering Network (AGCN) a\nnovel architecture that reinterprets the notion that graph is attention. AGCN\ndirectly embeds the attention mechanism into the graph structure, enabling\neffective global information extraction while maintaining sensitivity to local\ntopological cues. Our framework incorporates theoretical analysis to contrast\nAGCN behavior with GNN and Transformer and introduces two innovations: (1) a KV\ncache mechanism to improve computational efficiency, and (2) a pairwise margin\ncontrastive loss to boost the discriminative capacity of the attention space.\nExtensive experimental results demonstrate that AGCN outperforms\nstate-of-the-art methods.","summary":"This paper proposes the Attentive Graph Clustering Network (AGCN) to improve graph clustering by integrating attention mechanisms directly into graph structures. The study highlights the complementary weaknesses of GNNs and Transformers in this context.","authors":["Xuanting Xie","Bingheng Li","Erlin Pan","Rui Hou","Wenyu Chen","Zhao Kang"],"categories":["cs.LG","cs.AI","cs.NI"],"affiliations":["University of Electronic Science and Technology of China","Michigan State University","Alibaba Group"],"keywords":["Graph Clustering","Attention Mechanism","Graph Neural Networks","Transformer","Contrastive Learning"],"language":"en","published_date":"2025-09-18T14:51:13Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15024v1"}
{"arxiv_id":"2509.15011v1","title":"Sea-ing Through Scattered Rays: Revisiting the Image Formation Model for\n  Realistic Underwater Image Generation","abstract":"In recent years, the underwater image formation model has found extensive use\nin the generation of synthetic underwater data. Although many approaches focus\non scenes primarily affected by discoloration, they often overlook the model's\nability to capture the complex, distance-dependent visibility loss present in\nhighly turbid environments. In this work, we propose an improved synthetic data\ngeneration pipeline that includes the commonly omitted forward scattering term,\nwhile also considering a nonuniform medium. Additionally, we collected the\nBUCKET dataset under controlled turbidity conditions to acquire real turbid\nfootage with the corresponding reference images. Our results demonstrate\nqualitative improvements over the reference model, particularly under\nincreasing turbidity, with a selection rate of 82. 5\\% by survey participants.\nData and code can be accessed on the project page:\nvap.aau.dk\/sea-ing-through-scattered-rays.","summary":"This work proposes an improved synthetic data generation pipeline for underwater images, addressing visibility loss in turbid environments. The study includes the collection of the BUCKET dataset and demonstrates qualitative improvements over existing models.","authors":["Vasiliki Ismiroglou","Malte Pedersen","Stefan H. Bengtson","Andreas Aakerberg","Thomas B. Moeslund"],"categories":["cs.CV","cs.AI"],"affiliations":["Aalborg University","Pioneer Centre for Artificial Intelligence"],"keywords":["underwater imaging","synthetic data","visibility loss","turbidity","computer vision"],"language":"en","published_date":"2025-09-18T14:42:24Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.15011v1"}
{"arxiv_id":"2509.14998v1","title":"A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical\n  Decision-making","abstract":"Medical decision-making often involves integrating knowledge from multiple\nclinical specialties, typically achieved through multidisciplinary teams.\nInspired by this collaborative process, recent work has leveraged large\nlanguage models (LLMs) in multi-agent collaboration frameworks to emulate\nexpert teamwork. While these approaches improve reasoning through agent\ninteraction, they are limited by static, pre-assigned roles, which hinder\nadaptability and dynamic knowledge integration. To address these limitations,\nwe propose KAMAC, a Knowledge-driven Adaptive Multi-Agent Collaboration\nframework that enables LLM agents to dynamically form and expand expert teams\nbased on the evolving diagnostic context. KAMAC begins with one or more expert\nagents and then conducts a knowledge-driven discussion to identify and fill\nknowledge gaps by recruiting additional specialists as needed. This supports\nflexible, scalable collaboration in complex clinical scenarios, with decisions\nfinalized through reviewing updated agent comments. Experiments on two\nreal-world medical benchmarks demonstrate that KAMAC significantly outperforms\nboth single-agent and advanced multi-agent methods, particularly in complex\nclinical scenarios (i.e., cancer prognosis) requiring dynamic, cross-specialty\nexpertise. Our code is publicly available at:\nhttps:\/\/github.com\/XiaoXiao-Woo\/KAMAC.","summary":"The study presents KAMAC, a framework that enhances medical decision-making by enabling large language model agents to dynamically form expert teams. It addresses limitations of static roles in multi-agent collaboration, improving adaptability and knowledge integration.","authors":["Xiao Wu","Ting-Zhu Huang","Liang-Jian Deng","Yanyuan Qiao","Imran Razzak","Yutong Xie"],"categories":["cs.AI","cs.CV"],"affiliations":["Mohamed bin Zayed University of Artificial Intelligence","University of Electronic Science and Technology of China","Swiss Federal Institute of Technology Lausanne"],"keywords":["medical decision-making","large language models","multi-agent collaboration","dynamic knowledge integration","expert teams"],"language":"en","published_date":"2025-09-18T14:33:36Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14998v1"}
{"arxiv_id":"2509.14987v1","title":"Blockchain-Enabled Explainable AI for Trusted Healthcare Systems","abstract":"This paper introduces a Blockchain-Integrated Explainable AI Framework (BXHF)\nfor healthcare systems to tackle two essential challenges confronting health\ninformation networks: safe data exchange and comprehensible AI-driven clinical\ndecision-making. Our architecture incorporates blockchain, ensuring patient\nrecords are immutable, auditable, and tamper-proof, alongside Explainable AI\n(XAI) methodologies that yield transparent and clinically relevant model\npredictions. By incorporating security assurances and interpretability\nrequirements into a unified optimization pipeline, BXHF ensures both data-level\ntrust (by verified and encrypted record sharing) and decision-level trust (with\nauditable and clinically aligned explanations). Its hybrid edge-cloud\narchitecture allows for federated computation across different institutions,\nenabling collaborative analytics while protecting patient privacy. We\ndemonstrate the framework's applicability through use cases such as\ncross-border clinical research networks, uncommon illness detection and\nhigh-risk intervention decision support. By ensuring transparency,\nauditability, and regulatory compliance, BXHF improves the credibility, uptake,\nand effectiveness of AI in healthcare, laying the groundwork for safer and more\nreliable clinical decision-making.","summary":"This paper presents a Blockchain-Integrated Explainable AI Framework (BXHF) for healthcare systems to enhance data exchange and AI-driven decision-making. The framework ensures data integrity and interpretability, improving trust and effectiveness in clinical applications.","authors":["Md Talha Mohsin"],"categories":["cs.CR","cs.AI","cs.LG"],"affiliations":["University of Tulsa"],"keywords":["Blockchain","Explainable AI","Healthcare","Clinical Decision Support","Data Integrity"],"language":"en","published_date":"2025-09-18T14:17:19Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14987v1"}
{"arxiv_id":"2509.14984v1","title":"The Role of Touch: Towards Optimal Tactile Sensing Distribution in\n  Anthropomorphic Hands for Dexterous In-Hand Manipulation","abstract":"In-hand manipulation tasks, particularly in human-inspired robotic systems,\nmust rely on distributed tactile sensing to achieve precise control across a\nwide variety of tasks. However, the optimal configuration of this network of\nsensors is a complex problem, and while the fingertips are a common choice for\nplacing sensors, the contribution of tactile information from other regions of\nthe hand is often overlooked. This work investigates the impact of tactile\nfeedback from various regions of the fingers and palm in performing in-hand\nobject reorientation tasks. We analyze how sensory feedback from different\nparts of the hand influences the robustness of deep reinforcement learning\ncontrol policies and investigate the relationship between object\ncharacteristics and optimal sensor placement. We identify which tactile sensing\nconfigurations contribute to improving the efficiency and accuracy of\nmanipulation. Our results provide valuable insights for the design and use of\nanthropomorphic end-effectors with enhanced manipulation capabilities.","summary":"This work investigates the impact of tactile feedback from various regions of the hand on in-hand manipulation tasks. It analyzes how different tactile sensing configurations influence the efficiency and accuracy of robotic manipulation.","authors":["João Damião Almeida","Egidio Falotico","Cecilia Laschi","José Santos-Victor"],"categories":["cs.RO","cs.AI","cs.LG","cs.SY","eess.SY"],"affiliations":["Instituto Superior Técnico","National University of Singapore","Scuola Superiore Sant'Anna"],"keywords":["tactile sensing","deep reinforcement learning","human-inspired robotics","in-hand manipulation"],"language":"en","published_date":"2025-09-18T14:13:26Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14984v1"}
{"arxiv_id":"2509.14980v1","title":"M4Diffuser: Multi-View Diffusion Policy with Manipulability-Aware\n  Control for Robust Mobile Manipulation","abstract":"Mobile manipulation requires the coordinated control of a mobile base and a\nrobotic arm while simultaneously perceiving both global scene context and\nfine-grained object details. Existing single-view approaches often fail in\nunstructured environments due to limited fields of view, exploration, and\ngeneralization abilities. Moreover, classical controllers, although stable,\nstruggle with efficiency and manipulability near singularities. To address\nthese challenges, we propose M4Diffuser, a hybrid framework that integrates a\nMulti-View Diffusion Policy with a novel Reduced and Manipulability-aware QP\n(ReM-QP) controller for mobile manipulation. The diffusion policy leverages\nproprioceptive states and complementary camera perspectives with both\nclose-range object details and global scene context to generate task-relevant\nend-effector goals in the world frame. These high-level goals are then executed\nby the ReM-QP controller, which eliminates slack variables for computational\nefficiency and incorporates manipulability-aware preferences for robustness\nnear singularities. Comprehensive experiments in simulation and real-world\nenvironments show that M4Diffuser achieves 7 to 56 percent higher success rates\nand reduces collisions by 3 to 31 percent over baselines. Our approach\ndemonstrates robust performance for smooth whole-body coordination, and strong\ngeneralization to unseen tasks, paving the way for reliable mobile manipulation\nin unstructured environments. Details of the demo and supplemental material are\navailable on our project website https:\/\/sites.google.com\/view\/m4diffuser.","summary":"M4Diffuser is a hybrid framework that combines a Multi-View Diffusion Policy with a manipulability-aware controller for improved mobile manipulation. It enhances task success rates and reduces collisions in unstructured environments.","authors":["Ju Dong","Lei Zhang","Liding Zhang","Yao Ling","Yu Fu","Kaixin Bai","Zoltán-Csaba Márton","Zhenshan Bing","Zhaopeng Chen","Alois Christian Knoll","Jianwei Zhang"],"categories":["cs.RO","cs.AI","cs.CV"],"affiliations":["University of Hamburg","Technical University of Munich","Agile Robots SE"],"keywords":["Mobile Manipulation","Multi-View Diffusion Policy","Robustness","Manipulability","Whole-Body Control"],"language":"en","published_date":"2025-09-18T14:09:53Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14980v1"}
{"arxiv_id":"2509.14966v1","title":"RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D\n  Geometric Keypoint Matching","abstract":"The rapidly growing number of product categories in large-scale e-commerce\nmakes accurate object identification for automated packing in warehouses\nsubstantially more difficult. As the catalog grows, intra-class variability and\na long tail of rare or visually similar items increase, and when combined with\ndiverse packaging, cluttered containers, frequent occlusion, and large\nviewpoint changes-these factors amplify discrepancies between query and\nreference images, causing sharp performance drops for methods that rely solely\non 2D appearance features. Thus, we propose RoboEye, a two-stage identification\nframework that dynamically augments 2D semantic features with domain-adapted 3D\nreasoning and lightweight adapters to bridge training deployment gaps. In the\nfirst stage, we train a large vision model to extract 2D features for\ngenerating candidate rankings. A lightweight 3D-feature-awareness module then\nestimates 3D feature quality and predicts whether 3D re-ranking is necessary,\npreventing performance degradation and avoiding unnecessary computation. When\ninvoked, the second stage uses our robot 3D retrieval transformer, comprising a\n3D feature extractor that produces geometry-aware dense features and a\nkeypoint-based matcher that computes keypoint-correspondence confidences\nbetween query and reference images instead of conventional cosine-similarity\nscoring. Experiments show that RoboEye improves Recall@1 by 7.1% over the prior\nstate of the art (RoboLLM). Moreover, RoboEye operates using only RGB images,\navoiding reliance on explicit 3D inputs and reducing deployment costs. The code\nused in this paper is publicly available at:\nhttps:\/\/github.com\/longkukuhi\/RoboEye.","summary":"RoboEye is a two-stage framework that enhances 2D object identification in warehouses by integrating 3D geometric reasoning. It improves performance by dynamically augmenting 2D features with 3D insights, addressing challenges posed by diverse packaging and occlusions.","authors":["Xingwu Zhang","Guanxuan Li","Zhuocheng Zhang","Zijun Long"],"categories":["cs.CV","cs.AI","cs.RO"],"affiliations":["Hunan University"],"keywords":["robotic object identification","3D geometric features","automated packing","e-commerce","visual features"],"language":"en","published_date":"2025-09-18T13:59:24Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14966v1"}
{"arxiv_id":"2509.14963v1","title":"Set Contribution Functions for Quantitative Bipolar Argumentation and\n  their Principles","abstract":"We present functions that quantify the contribution of a set of arguments in\nquantitative bipolar argumentation graphs to (the final strength of) an\nargument of interest, a so-called topic. Our set contribution functions are\ngeneralizations of existing functions that quantify the contribution of a\nsingle contributing argument to a topic. Accordingly, we generalize existing\ncontribution function principles for set contribution functions and provide a\ncorresponding principle-based analysis. We introduce new principles specific to\nset-based functions that focus on properties pertaining to the interaction of\narguments within a set. Finally, we sketch how the principles play out across\ndifferent set contribution functions given a recommendation system application\nscenario.","summary":"This paper presents functions that quantify the contribution of sets of arguments in quantitative bipolar argumentation graphs. It generalizes existing principles and introduces new principles specific to set-based functions.","authors":["Filip Naudot","Andreas Brännström","Vicenç Torra","Timotheus Kampik"],"categories":["cs.AI"],"affiliations":["Umeå University"],"keywords":["Quantitative Argumentation","Explainable AI","Automated Reasoning"],"language":"en","published_date":"2025-09-18T13:52:53Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14963v1"}
{"arxiv_id":"2509.14959v1","title":"Discrete optimal transport is a strong audio adversarial attack","abstract":"In this paper, we show that discrete optimal transport (DOT) is an effective\nblack-box adversarial attack against modern audio anti-spoofing countermeasures\n(CMs). Our attack operates as a post-processing, distribution-alignment step:\nframe-level WavLM embeddings of generated speech are aligned to an unpaired\nbona fide pool via entropic OT and a top-$k$ barycentric projection, then\ndecoded with a neural vocoder. Evaluated on ASVspoof2019 and ASVspoof5 with\nAASIST baselines, DOT yields consistently high equal error rate (EER) across\ndatasets and remains competitive after CM fine-tuning, outperforming several\nconventional attacks in cross-dataset transfer. Ablation analysis highlights\nthe practical impact of vocoder overlap. Results indicate that\ndistribution-level alignment is a powerful and stable attack surface for\ndeployed CMs.","summary":"This paper demonstrates that discrete optimal transport (DOT) is an effective black-box adversarial attack against audio anti-spoofing countermeasures. The method aligns WavLM embeddings to a bona fide pool, yielding high equal error rates across datasets.","authors":["Anton Selitskiy","Akib Shahriyar","Jishnuraj Prakasan"],"categories":["eess.AS","cs.AI"],"affiliations":["University of Rochester","Rochester Institute of Technology"],"keywords":["Optimal transport","adversarial attack","audio","ASVspoof","black-box"],"language":"en","published_date":"2025-09-18T13:46:16Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14959v1"}
{"arxiv_id":"2509.14956v1","title":"Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent\n  Systems","abstract":"This paper proposes a novel architectural framework aimed at enhancing\nsecurity and reliability in multi-agent systems (MAS). A central component of\nthis framework is a network of Sentinel Agents, functioning as a distributed\nsecurity layer that integrates techniques such as semantic analysis via large\nlanguage models (LLMs), behavioral analytics, retrieval-augmented verification,\nand cross-agent anomaly detection. Such agents can potentially oversee\ninter-agent communications, identify potential threats, enforce privacy and\naccess controls, and maintain comprehensive audit records. Complementary to the\nidea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator\nAgent supervises policy implementation, and manages agent participation. In\naddition, the Coordinator also ingests alerts from Sentinel Agents. Based on\nthese alerts, it can adapt policies, isolate or quarantine misbehaving agents,\nand contain threats to maintain the integrity of the MAS ecosystem. This\ndual-layered security approach, combining the continuous monitoring of Sentinel\nAgents with the governance functions of Coordinator Agents, supports dynamic\nand adaptive defense mechanisms against a range of threats, including prompt\ninjection, collusive agent behavior, hallucinations generated by LLMs, privacy\nbreaches, and coordinated multi-agent attacks. In addition to the architectural\ndesign, we present a simulation study where 162 synthetic attacks of different\nfamilies (prompt injection, hallucination, and data exfiltration) were injected\ninto a multi-agent conversational environment. The Sentinel Agents successfully\ndetected the attack attempts, confirming the practical feasibility of the\nproposed monitoring approach. The framework also offers enhanced system\nobservability, supports regulatory compliance, and enables policy evolution\nover time.","summary":"This paper proposes a novel architectural framework for enhancing security and reliability in multi-agent systems using Sentinel Agents. It includes a simulation study demonstrating the agents' effectiveness in detecting various attack attempts.","authors":["Diego Gosmar","Deborah A. Dahl"],"categories":["cs.AI","cs.MA"],"affiliations":["Tesisquare","Voiceinteroperability.ai","Linux Foundation AI & Data","Conversational Technologies"],"keywords":["Multi-Agent Systems","Sentinel Agents","Security","AI Observability","Attack Simulation"],"language":"en","published_date":"2025-09-18T13:39:59Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14956v1"}
{"arxiv_id":"2509.14944v1","title":"Estimating Respiratory Effort from Nocturnal Breathing Sounds for\n  Obstructive Sleep Apnoea Screening","abstract":"Obstructive sleep apnoea (OSA) is a prevalent condition with significant\nhealth consequences, yet many patients remain undiagnosed due to the complexity\nand cost of over-night polysomnography. Acoustic-based screening provides a\nscalable alternative, yet performance is limited by environmental noise and the\nlack of physiological context. Respiratory effort is a key signal used in\nclinical scoring of OSA events, but current approaches require additional\ncontact sensors that reduce scalability and patient comfort. This paper\npresents the first study to estimate respiratory effort directly from nocturnal\naudio, enabling physiological context to be recovered from sound alone. We\npropose a latent-space fusion framework that integrates the estimated effort\nembeddings with acoustic features for OSA detection. Using a dataset of 157\nnights from 103 participants recorded in home environments, our respiratory\neffort estimator achieves a concordance correlation coefficient of 0.48,\ncapturing meaningful respiratory dynamics. Fusing effort and audio improves\nsensitivity and AUC over audio-only baselines, especially at low\napnoea-hypopnoea index thresholds. The proposed approach requires only\nsmartphone audio at test time, which enables sensor-free, scalable, and\nlongitudinal OSA monitoring.","summary":"This study presents a novel method to estimate respiratory effort from nocturnal audio for obstructive sleep apnoea detection. The proposed approach enhances screening performance while maintaining scalability and comfort for patients.","authors":["Xiaolei Xu","Chaoyue Niu","Guy J. Brown","Hector Romero","Ning Ma"],"categories":["cs.SD","cs.AI","eess.AS"],"affiliations":["University of Sheffield","Passion for Life Healthcare"],"keywords":["obstructive sleep apnoea","acoustic-based detection","respiratory effort","nocturnal breathing sounds","sensor-free monitoring"],"language":"en","published_date":"2025-09-18T13:31:19Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14944v1"}
{"arxiv_id":"2509.14942v1","title":"Explainable AI for Infection Prevention and Control: Modeling CPE\n  Acquisition and Patient Outcomes in an Irish Hospital with Transformers","abstract":"Carbapenemase-Producing Enterobacteriace poses a critical concern for\ninfection prevention and control in hospitals. However, predictive modeling of\npreviously highlighted CPE-associated risks such as readmission, mortality, and\nextended length of stay (LOS) remains underexplored, particularly with modern\ndeep learning approaches. This study introduces an eXplainable AI modeling\nframework to investigate CPE impact on patient outcomes from Electronic Medical\nRecords data of an Irish hospital. We analyzed an inpatient dataset from an\nIrish acute hospital, incorporating diagnostic codes, ward transitions, patient\ndemographics, infection-related variables and contact network features. Several\nTransformer-based architectures were benchmarked alongside traditional machine\nlearning models. Clinical outcomes were predicted, and XAI techniques were\napplied to interpret model decisions. Our framework successfully demonstrated\nthe utility of Transformer-based models, with TabTransformer consistently\noutperforming baselines across multiple clinical prediction tasks, especially\nfor CPE acquisition (AUROC and sensitivity). We found infection-related\nfeatures, including historical hospital exposure, admission context, and\nnetwork centrality measures, to be highly influential in predicting patient\noutcomes and CPE acquisition risk. Explainability analyses revealed that\nfeatures like \"Area of Residence\", \"Admission Ward\" and prior admissions are\nkey risk factors. Network variables like \"Ward PageRank\" also ranked highly,\nreflecting the potential value of structural exposure information. This study\npresents a robust and explainable AI framework for analyzing complex EMR data\nto identify key risk factors and predict CPE-related outcomes. Our findings\nunderscore the superior performance of the Transformer models and highlight the\nimportance of diverse clinical and network features.","summary":"This study presents an eXplainable AI framework to model the impact of Carbapenemase-Producing Enterobacteriace on patient outcomes using data from an Irish hospital. It highlights the effectiveness of Transformer-based models in predicting clinical outcomes.","authors":["Minh-Khoi Pham","Tai Tan Mai","Martin Crane","Rob Brennan","Marie E. Ward","Una Geary","Declan Byrne","Brian O Connell","Colm Bergin","Donncha Creagh","Nick McDonald","Marija Bezbradica"],"categories":["cs.AI","cs.LG"],"affiliations":["Dublin City University","ADAPT Centre","University College Dublin","St James’s Hospital","Health Service Executive","Trinity College Dublin"],"keywords":["Explainable AI","CPE","predictive modeling","patient outcomes","Transformers"],"language":"en","published_date":"2025-09-18T13:29:11Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14942v1"}
{"arxiv_id":"2509.14930v1","title":"Cross-Modal Knowledge Distillation for Speech Large Language Models","abstract":"In this work, we present the first systematic evaluation of catastrophic\nforgetting and modality inequivalence in speech large language models, showing\nthat introducing speech capabilities can degrade knowledge and reasoning even\nwhen inputs remain textual, and performance further decreases with spoken\nqueries. To address these challenges, we propose a cross-modal knowledge\ndistillation framework that leverages both text-to-text and speech-to-text\nchannels to transfer knowledge from a text-based teacher model to a speech LLM.\nExtensive experiments on dialogue and audio understanding tasks validate the\neffectiveness of our approach in preserving textual knowledge, improving\ncross-modal alignment, and enhancing reasoning in speech-based interactions.","summary":"This work evaluates catastrophic forgetting and modality inequivalence in speech large language models, proposing a cross-modal knowledge distillation framework. Experiments validate its effectiveness in preserving knowledge and enhancing reasoning in speech-based interactions.","authors":["Enzhi Wang","Qicheng Li","Zhiyuan Tang","Yuhang Jia"],"categories":["cs.CL","cs.AI"],"affiliations":["Nankai University","Tencent Corporation"],"keywords":["Speech LLMs","Cross-Modal Knowledge Distillation","Catastrophic Forgetting","Modality Inequivalence","Question Answering"],"language":"en","published_date":"2025-09-18T13:07:53Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14930v1"}
{"arxiv_id":"2509.14926v1","title":"Patent Language Model Pretraining with ModernBERT","abstract":"Transformer-based language models such as BERT have become foundational in\nNLP, yet their performance degrades in specialized domains like patents, which\ncontain long, technical, and legally structured text. Prior approaches to\npatent NLP have primarily relied on fine-tuning general-purpose models or\ndomain-adapted variants pretrained with limited data. In this work, we pretrain\n3 domain-specific masked language models for patents, using the ModernBERT\narchitecture and a curated corpus of over 60 million patent records. Our\napproach incorporates architectural optimizations, including FlashAttention,\nrotary embeddings, and GLU feed-forward layers. We evaluate our models on four\ndownstream patent classification tasks. Our model, ModernBERT-base-PT,\nconsistently outperforms the general-purpose ModernBERT baseline on three out\nof four datasets and achieves competitive performance with a baseline\nPatentBERT. Additional experiments with ModernBERT-base-VX and\nMosaic-BERT-large demonstrate that scaling the model size and customizing the\ntokenizer further enhance performance on selected tasks. Notably, all\nModernBERT variants retain substantially faster inference over - 3x that of\nPatentBERT - underscoring their suitability for time-sensitive applications.\nThese results underscore the benefits of domain-specific pretraining and\narchitectural improvements for patent-focused NLP tasks.","summary":"This work presents the pretraining of domain-specific masked language models for patents using the ModernBERT architecture. The models demonstrate superior performance on patent classification tasks compared to general-purpose models.","authors":["Amirhossein Yousefiramandi","Ciaran Cooney"],"categories":["cs.CL","cs.AI","cs.LG"],"affiliations":["Clarivate"],"keywords":["Patent NLP","ModernBERT","Domain-specific pretraining","Transformer models","Architectural optimizations"],"language":"en","published_date":"2025-09-18T13:04:30Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14926v1"}
{"arxiv_id":"2509.14912v1","title":"Back to Ear: Perceptually Driven High Fidelity Music Reconstruction","abstract":"Variational Autoencoders (VAEs) are essential for large-scale audio tasks\nlike diffusion-based generation. However, existing open-source models often\nneglect auditory perceptual aspects during training, leading to weaknesses in\nphase accuracy and stereophonic spatial representation. To address these\nchallenges, we propose {\\epsilon}ar-VAE, an open-source music signal\nreconstruction model that rethinks and optimizes the VAE training paradigm. Our\ncontributions are threefold: (i) A K-weighting perceptual filter applied prior\nto loss calculation to align the objective with auditory perception. (ii) Two\nnovel phase losses: a Correlation Loss for stereo coherence, and a Phase Loss\nusing its derivatives--Instantaneous Frequency and Group Delay--for precision.\n(iii) A new spectral supervision paradigm where magnitude is supervised by all\nfour Mid\/Side\/Left\/Right components, while phase is supervised only by the LR\ncomponents. Experiments show {\\epsilon}ar-VAE at 44.1kHz substantially\noutperforms leading open-source models across diverse metrics, showing\nparticular strength in reconstructing high-frequency harmonics and the spatial\ncharacteristics.","summary":"The paper introduces ϵar-VAE, an open-source model for high-fidelity music reconstruction that optimizes the VAE training paradigm. It incorporates perceptual filters and novel loss functions to enhance phase accuracy and spatial representation.","authors":["Kangdi Wang","Zhiyue Wu","Dinghao Zhou","Rui Lin","Junyu Dai","Tao Jiang"],"categories":["cs.SD","cs.AI"],"affiliations":["ϵar-LAB","initi-AI Ltd"],"keywords":["Variational Autoencoders","music reconstruction","perceptual weighting","phase coherence","high-fidelity audio"],"language":"en","published_date":"2025-09-18T12:41:34Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14912v1"}
{"arxiv_id":"2509.14886v1","title":"A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation","abstract":"The rapid progress of Multi-Modal Large Language Models (MLLMs) has spurred\nthe creation of numerous benchmarks. However, conventional full-coverage\nQuestion-Answering evaluations suffer from high redundancy and low efficiency.\nInspired by human interview processes, we propose a multi-to-one interview\nparadigm for efficient MLLM evaluation. Our framework consists of (i) a\ntwo-stage interview strategy with pre-interview and formal interview phases,\n(ii) dynamic adjustment of interviewer weights to ensure fairness, and (iii) an\nadaptive mechanism for question difficulty-level chosen. Experiments on\ndifferent benchmarks show that the proposed paradigm achieves significantly\nhigher correlation with full-coverage results than random sampling, with\nimprovements of up to 17.6% in PLCC and 16.7% in SRCC, while reducing the\nnumber of required questions. These findings demonstrate that the proposed\nparadigm provides a reliable and efficient alternative for large-scale MLLM\nbenchmarking.","summary":"This paper proposes a multi-to-one interview paradigm for efficient evaluation of Multi-Modal Large Language Models (MLLMs), addressing issues of redundancy and low efficiency in conventional evaluations. The framework includes a two-stage interview strategy and dynamic adjustments to improve reliability and fairness in benchmarking.","authors":["Ye Shen","Junying Wang","Farong Wen","Yijin Guo","Qi Jia","Zicheng Zhang","Guangtao Zhai"],"categories":["cs.CL","cs.AI"],"affiliations":["Shanghai Jiao Tong University","Shanghai AI Laboratory","Fudan University"],"keywords":["MLLM Evaluation","Multi-To-One Interview","Efficiency","Benchmarking","Question-Answering"],"language":"en","published_date":"2025-09-18T12:07:40Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14886v1"}
{"arxiv_id":"2509.14877v1","title":"AI-Driven Multi-Agent Vehicular Planning for Battery Efficiency and QoS\n  in 6G Smart Cities","abstract":"While simulators exist for vehicular IoT nodes communicating with the Cloud\nthrough Edge nodes in a fully-simulated osmotic architecture, they often lack\nsupport for dynamic agent planning and optimisation to minimise vehicular\nbattery consumption while ensuring fair communication times. Addressing these\nchallenges requires extending current simulator architectures with AI\nalgorithms for both traffic prediction and dynamic agent planning. This paper\npresents an extension of SimulatorOrchestrator (SO) to meet these requirements.\nPreliminary results over a realistic urban dataset show that utilising\nvehicular planning algorithms can lead to improved battery and QoS performance\ncompared with traditional shortest path algorithms. The additional inclusion of\ndesirability areas enabled more ambulances to be routed to their target\ndestinations while utilising less energy to do so, compared to traditional and\nweighted algorithms without desirability considerations.","summary":"This paper presents an extension of SimulatorOrchestrator to improve vehicular battery efficiency and QoS in smart cities using AI-driven multi-agent planning. Preliminary results indicate enhanced performance over traditional algorithms.","authors":["Rohin Gillgallon","Giacomo Bergami","Reham Almutairi","Graham Morgan"],"categories":["cs.NI","cs.AI","cs.ET"],"affiliations":["Newcastle University","University of Hafr Albatin"],"keywords":["6G","AI","Battery Optimization","Traffic Prediction","Vehicular Networks"],"language":"en","published_date":"2025-09-18T11:46:22Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14877v1"}
{"arxiv_id":"2509.14868v1","title":"DPANet: Dual Pyramid Attention Network for Multivariate Time Series\n  Forecasting","abstract":"We conducted rigorous ablation studies to validate DPANet's key components\n(Table \\ref{tab:ablation-study}). The full model consistently outperforms all\nvariants. To test our dual-domain hypothesis, we designed two specialized\nversions: a Temporal-Only model (fusing two identical temporal pyramids) and a\nFrequency-Only model (fusing two spectral pyramids). Both variants\nunderperformed significantly, confirming that the fusion of heterogeneous\ntemporal and frequency information is critical. Furthermore, replacing the\ncross-attention mechanism with a simpler method (w\/o Cross-Fusion) caused the\nmost severe performance degradation. This result underscores that our\ninteractive fusion block is the most essential component.","summary":"The Dual Pyramid Attention Network (DPANet) is proposed to improve long-term time series forecasting by modeling complex dependencies across multiple temporal scales and frequency resolutions. Extensive experiments demonstrate its state-of-the-art performance compared to prior models.","authors":["Qianyang Li","Xingjun Zhang","Shaoxun Wang","Jia Wei"],"categories":["cs.LG","cs.AI"],"affiliations":["Xi’an Jiaotong University","Tsinghua University"],"keywords":["Time Series Forecasting","Attention Mechanism","Multi-Scale Learning","Pyramid Network","Deep Learning"],"language":"en","published_date":"2025-09-18T11:35:21Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14868v1"}
{"arxiv_id":"2509.14863v1","title":"Exploring the Global-to-Local Attention Scheme in Graph Transformers: An\n  Empirical Study","abstract":"Graph Transformers (GTs) show considerable potential in graph representation\nlearning. The architecture of GTs typically integrates Graph Neural Networks\n(GNNs) with global attention mechanisms either in parallel or as a precursor to\nattention mechanisms, yielding a local-and-global or local-to-global attention\nscheme. However, as the global attention mechanism primarily captures\nlong-range dependencies between nodes, these integration schemes may suffer\nfrom information loss, where the local neighborhood information learned by GNN\ncould be diluted by the attention mechanism. Therefore, we propose G2LFormer,\nfeaturing a novel global-to-local attention scheme where the shallow network\nlayers use attention mechanisms to capture global information, while the deeper\nlayers employ GNN modules to learn local structural information, thereby\npreventing nodes from ignoring their immediate neighbors. An effective\ncross-layer information fusion strategy is introduced to allow local layers to\nretain beneficial information from global layers and alleviate information\nloss, with acceptable trade-offs in scalability. To validate the feasibility of\nthe global-to-local attention scheme, we compare G2LFormer with\nstate-of-the-art linear GTs and GNNs on node-level and graph-level tasks. The\nresults indicate that G2LFormer exhibits excellent performance while keeping\nlinear complexity.","summary":"This study introduces G2LFormer, a novel global-to-local attention scheme that integrates Graph Neural Networks with attention mechanisms. The approach aims to enhance graph representation learning by preventing information loss and improving performance on node-level and graph-level tasks.","authors":["Zhengwei Wang","Gang Wu"],"categories":["cs.LG","cs.AI"],"affiliations":["Northeastern University"],"keywords":["Graph Transformers","Graph Neural Networks","attention mechanisms","information loss","G2LFormer"],"language":"en","published_date":"2025-09-18T11:30:50Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14863v1"}
{"arxiv_id":"2509.14860v1","title":"MARIC: Multi-Agent Reasoning for Image Classification","abstract":"Image classification has traditionally relied on parameter-intensive model\ntraining, requiring large-scale annotated datasets and extensive fine tuning to\nachieve competitive performance. While recent vision language models (VLMs)\nalleviate some of these constraints, they remain limited by their reliance on\nsingle pass representations, often failing to capture complementary aspects of\nvisual content. In this paper, we introduce Multi Agent based Reasoning for\nImage Classification (MARIC), a multi agent framework that reformulates image\nclassification as a collaborative reasoning process. MARIC first utilizes an\nOutliner Agent to analyze the global theme of the image and generate targeted\nprompts. Based on these prompts, three Aspect Agents extract fine grained\ndescriptions along distinct visual dimensions. Finally, a Reasoning Agent\nsynthesizes these complementary outputs through integrated reflection step,\nproducing a unified representation for classification. By explicitly\ndecomposing the task into multiple perspectives and encouraging reflective\nsynthesis, MARIC mitigates the shortcomings of both parameter-heavy training\nand monolithic VLM reasoning. Experiments on 4 diverse image classification\nbenchmark datasets demonstrate that MARIC significantly outperforms baselines,\nhighlighting the effectiveness of multi-agent visual reasoning for robust and\ninterpretable image classification.","summary":"MARIC introduces a multi-agent framework for image classification that enhances accuracy and interpretability by decomposing the task into collaborative reasoning processes. Experiments show significant performance improvements over traditional methods.","authors":["Wonduk Seo","Minhyeong Yu","Hyunjin An","Seunghyun Lee"],"categories":["cs.CV","cs.AI","cs.CL","cs.MA"],"affiliations":["Enhans"],"keywords":["Image Classification","Multi-Agent Reasoning","Vision Language Models","Collaborative Reasoning","Interpretability"],"language":"en","published_date":"2025-09-18T11:27:00Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14860v1"}
{"arxiv_id":"2509.14858v1","title":"MeanFlowSE: one-step generative speech enhancement via conditional mean\n  flow","abstract":"Multistep inference is a bottleneck for real-time generative speech\nenhancement because flow- and diffusion-based systems learn an instantaneous\nvelocity field and therefore rely on iterative ordinary differential equation\n(ODE) solvers. We introduce MeanFlowSE, a conditional generative model that\nlearns the average velocity over finite intervals along a trajectory. Using a\nJacobian-vector product (JVP) to instantiate the MeanFlow identity, we derive a\nlocal training objective that directly supervises finite-interval displacement\nwhile remaining consistent with the instantaneous-field constraint on the\ndiagonal. At inference, MeanFlowSE performs single-step generation via a\nbackward-in-time displacement, removing the need for multistep solvers; an\noptional few-step variant offers additional refinement. On VoiceBank-DEMAND,\nthe single-step model achieves strong intelligibility, fidelity, and perceptual\nquality with substantially lower computational cost than multistep baselines.\nThe method requires no knowledge distillation or external teachers, providing\nan efficient, high-fidelity framework for real-time generative speech\nenhancement.","summary":"MeanFlowSE is a conditional generative model for speech enhancement that learns average velocity over finite intervals, enabling single-step generation. It achieves high intelligibility and fidelity with lower computational costs compared to multistep methods.","authors":["Duojia Li","Shenghui Lu","Hongchen Pan","Zongyi Zhan","Qingyang Hong","Lin Li"],"categories":["cs.SD","cs.AI"],"affiliations":["Xiamen University"],"keywords":["speech enhancement","generative models","flow matching","mean flow","one-step inference"],"language":"en","published_date":"2025-09-18T11:24:47Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14858v1"}
{"arxiv_id":"2509.14851v1","title":"Empathy-R1: A Chain-of-Empathy and Reinforcement Learning Framework for\n  Long-Form Mental Health Support","abstract":"Empathy is critical for effective mental health support, especially when\naddressing Long Counseling Texts (LCTs). However, existing Large Language\nModels (LLMs) often generate replies that are semantically fluent but lack the\nstructured reasoning necessary for genuine psychological support, particularly\nin a Chinese context. To bridge this gap, we introduce Empathy-R1, a novel\nframework that integrates a Chain-of-Empathy (CoE) reasoning process with\nReinforcement Learning (RL) to enhance response quality for LCTs. Inspired by\ncognitive-behavioral therapy, our CoE paradigm guides the model to sequentially\nreason about a help-seeker's emotions, causes, and intentions, making its\nthinking process both transparent and interpretable. Our framework is empowered\nby a new large-scale Chinese dataset, Empathy-QA, and a two-stage training\nprocess. First, Supervised Fine-Tuning instills the CoE's reasoning structure.\nSubsequently, RL, guided by a dedicated reward model, refines the therapeutic\nrelevance and contextual appropriateness of the final responses. Experiments\nshow that Empathy-R1 achieves strong performance on key automatic metrics. More\nimportantly, human evaluations confirm its superiority, showing a clear\npreference over strong baselines and achieving a Win@1 rate of 44.30% on our\nnew benchmark. By enabling interpretable and contextually nuanced responses,\nEmpathy-R1 represents a significant advancement in developing responsible and\ngenuinely beneficial AI for mental health support.","summary":"Empathy-R1 is a novel framework that combines Chain-of-Empathy reasoning with Reinforcement Learning to improve response quality for Long Counseling Texts in mental health support. It enhances the interpretability and contextual relevance of AI-generated responses, demonstrating superior performance in evaluations.","authors":["Xianrong Yao","Dong She","Chenxu Zhang","Yimeng Zhang","Yueru Sun","Noman Ahmed","Yang Gao","Zhanpeng Jin"],"categories":["cs.CL","cs.AI"],"affiliations":["South China University of Technology"],"keywords":["Empathy","Reinforcement Learning","Mental Health Support","Large Language Models","Cognitive-Behavioral Therapy"],"language":"en","published_date":"2025-09-18T11:16:09Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14851v1"}
{"arxiv_id":"2509.14846v1","title":"[Re] Improving Interpretation Faithfulness for Vision Transformers","abstract":"This work aims to reproduce the results of Faithful Vision Transformers\n(FViTs) proposed by arXiv:2311.17983 alongside interpretability methods for\nVision Transformers from arXiv:2012.09838 and Xu (2022) et al. We investigate\nclaims made by arXiv:2311.17983, namely that the usage of Diffusion Denoised\nSmoothing (DDS) improves interpretability robustness to (1) attacks in a\nsegmentation task and (2) perturbation and attacks in a classification task. We\nalso extend the original study by investigating the authors' claims that adding\nDDS to any interpretability method can improve its robustness under attack.\nThis is tested on baseline methods and the recently proposed Attribution\nRollout method. In addition, we measure the computational costs and\nenvironmental impact of obtaining an FViT through DDS. Our results broadly\nagree with the original study's findings, although minor discrepancies were\nfound and discussed.","summary":"This work reproduces results of Faithful Vision Transformers and investigates the impact of Diffusion Denoised Smoothing on interpretability robustness. The findings broadly align with the original study, with some minor discrepancies discussed.","authors":["Izabela Kurek","Wojciech Trejter","Stipe Frkovic","Andro Erdelez"],"categories":["cs.CV","cs.AI"],"affiliations":["University of Amsterdam"],"keywords":["Vision Transformers","interpretability","robustness","Diffusion Denoised Smoothing","computational costs"],"language":"en","published_date":"2025-09-18T11:11:27Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14846v1"}
{"arxiv_id":"2509.14841v1","title":"Not All Degradations Are Equal: A Targeted Feature Denoising Framework\n  for Generalizable Image Super-Resolution","abstract":"Generalizable Image Super-Resolution aims to enhance model generalization\ncapabilities under unknown degradations. To achieve this goal, the models are\nexpected to focus only on image content-related features instead of overfitting\ndegradations. Recently, numerous approaches such as Dropout and Feature\nAlignment have been proposed to suppress models' natural tendency to overfit\ndegradations and yield promising results. Nevertheless, these works have\nassumed that models overfit to all degradation types (e.g., blur, noise, JPEG),\nwhile through careful investigations in this paper, we discover that models\npredominantly overfit to noise, largely attributable to its distinct\ndegradation pattern compared to other degradation types. In this paper, we\npropose a targeted feature denoising framework, comprising noise detection and\ndenoising modules. Our approach presents a general solution that can be\nseamlessly integrated with existing super-resolution models without requiring\narchitectural modifications. Our framework demonstrates superior performance\ncompared to previous regularization-based methods across five traditional\nbenchmarks and datasets, encompassing both synthetic and real-world scenarios.","summary":"This paper presents a targeted feature denoising framework for generalizable image super-resolution, addressing the issue of model overfitting to noise. The proposed approach integrates seamlessly with existing models and shows superior performance across various benchmarks.","authors":["Hongjun Wang","Jiyuan Chen","Zhengwei Yin","Xuan Song","Yinqiang Zheng"],"categories":["cs.CV","cs.AI"],"affiliations":["The University of Tokyo","The Hong Kong Polytechnic University","Jilin University"],"keywords":["Image Super-Resolution","Denoising","Generalization","Degradation","Deep Learning"],"language":"en","published_date":"2025-09-18T11:04:51Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14841v1"}
{"arxiv_id":"2509.14832v1","title":"Diffusion-Based Scenario Tree Generation for Multivariate Time Series\n  Prediction and Multistage Stochastic Optimization","abstract":"Stochastic forecasting is critical for efficient decision-making in uncertain\nsystems, such as energy markets and finance, where estimating the full\ndistribution of future scenarios is essential. We propose Diffusion Scenario\nTree (DST), a general framework for constructing scenario trees for\nmultivariate prediction tasks using diffusion-based probabilistic forecasting\nmodels. DST recursively samples future trajectories and organizes them into a\ntree via clustering, ensuring non-anticipativity (decisions depending only on\nobserved history) at each stage. We evaluate the framework on the optimization\ntask of energy arbitrage in New York State's day-ahead electricity market.\nExperimental results show that our approach consistently outperforms the same\noptimization algorithms that use scenario trees from more conventional models\nand Model-Free Reinforcement Learning baselines. Furthermore, using DST for\nstochastic optimization yields more efficient decision policies, achieving\nhigher performance by better handling uncertainty than deterministic and\nstochastic MPC variants using the same diffusion-based forecaster.","summary":"The paper presents the Diffusion Scenario Tree (DST) framework for constructing scenario trees using diffusion-based probabilistic forecasting models. It demonstrates superior performance in multistage stochastic optimization for energy arbitrage compared to traditional methods.","authors":["Stelios Zarifis","Ioannis Kordonis","Petros Maragos"],"categories":["cs.LG","cs.AI","cs.SY","eess.SY","I.2.6; I.5.1"],"affiliations":["Athena Research Center","Hellenic Robotics Center of Excellence","National Technical University of Athens"],"keywords":["Diffusion Models","Scenario Trees","Stochastic Optimization","Energy Markets","Uncertainty Quantification"],"language":"en","published_date":"2025-09-18T10:49:05Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14832v1"}
{"arxiv_id":"2509.14830v1","title":"ProtoMedX: Towards Explainable Multi-Modal Prototype Learning for Bone\n  Health Classification","abstract":"Bone health studies are crucial in medical practice for the early detection\nand treatment of Osteopenia and Osteoporosis. Clinicians usually make a\ndiagnosis based on densitometry (DEXA scans) and patient history. The\napplications of AI in this field are ongoing research. Most successful methods\nrely on deep learning models that use vision alone (DEXA\/X-ray imagery) and\nfocus on prediction accuracy, while explainability is often disregarded and\nleft to post hoc assessments of input contributions. We propose ProtoMedX, a\nmulti-modal model that uses both DEXA scans of the lumbar spine and patient\nrecords. ProtoMedX's prototype-based architecture is explainable by design,\nwhich is crucial for medical applications, especially in the context of the\nupcoming EU AI Act, as it allows explicit analysis of model decisions,\nincluding incorrect ones. ProtoMedX demonstrates state-of-the-art performance\nin bone health classification while also providing explanations that can be\nvisually understood by clinicians. Using a dataset of 4,160 real NHS patients,\nthe proposed ProtoMedX achieves 87.58% accuracy in vision-only tasks and 89.8%\nin its multi-modal variant, both surpassing existing published methods.","summary":"ProtoMedX is a multi-modal model for bone health classification that integrates DEXA scans and patient records, achieving high accuracy while providing explainable results. This approach addresses limitations in existing methods by ensuring model decisions are interpretable for clinicians.","authors":["Alvaro Lopez Pellicer","Andre Mariucci","Plamen Angelov","Marwan Bukhari","Jemma G. Kerns"],"categories":["cs.CV","cs.AI","cs.LG"],"affiliations":["Lancaster University"],"keywords":["Bone Health","AI","Explainability","Deep Learning","Classification"],"language":"en","published_date":"2025-09-18T10:46:18Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14830v1"}
{"arxiv_id":"2509.14827v1","title":"Template-Based Cortical Surface Reconstruction with Minimal Energy\n  Deformation","abstract":"Cortical surface reconstruction (CSR) from magnetic resonance imaging (MRI)\nis fundamental to neuroimage analysis, enabling morphological studies of the\ncerebral cortex and functional brain mapping. Recent advances in learning-based\nCSR have dramatically accelerated processing, allowing for reconstructions\nthrough the deformation of anatomical templates within seconds. However,\nensuring the learned deformations are optimal in terms of deformation energy\nand consistent across training runs remains a particular challenge. In this\nwork, we design a Minimal Energy Deformation (MED) loss, acting as a\nregularizer on the deformation trajectories and complementing the widely used\nChamfer distance in CSR. We incorporate it into the recent V2C-Flow model and\ndemonstrate considerable improvements in previously neglected training\nconsistency and reproducibility without harming reconstruction accuracy and\ntopological correctness.","summary":"This work presents a Minimal Energy Deformation loss for cortical surface reconstruction, enhancing training consistency and reproducibility. It integrates with the V2C-Flow model, improving efficiency without compromising accuracy.","authors":["Patrick Madlindl","Fabian Bongratz","Christian Wachinger"],"categories":["cs.CV","cs.AI","cs.LG","q-bio.NC","stat.ML"],"affiliations":["Technical University of Munich","Munich Center for Machine Learning"],"keywords":["Cortical surface reconstruction","Regularization","Reproducibility","Deformation","MRI"],"language":"en","published_date":"2025-09-18T10:41:39Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14827v1"}
{"arxiv_id":"2509.14803v1","title":"OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive\n  Support in Online Learning","abstract":"In online learning environments, students often lack personalized peer\ninteractions, which play a crucial role in supporting cognitive development and\nlearning engagement. Although previous studies have utilized large language\nmodels (LLMs) to simulate interactive dynamic learning environments for\nstudents, these interactions remain limited to conversational exchanges,\nlacking insights and adaptations to the learners' individualized learning and\ncognitive states. As a result, students' interest in discussions with AI\nlearning companions is low, and they struggle to gain inspiration from such\ninteractions. To address this challenge, we propose OnlineMate, a multi-agent\nlearning companion system driven by LLMs that integrates the Theory of Mind\n(ToM). OnlineMate is capable of simulating peer-like agent roles, adapting to\nlearners' cognitive states during collaborative discussions, and inferring\ntheir psychological states, such as misunderstandings, confusion, or\nmotivation. By incorporating Theory of Mind capabilities, the system can\ndynamically adjust its interaction strategies to support the development of\nhigher-order thinking and cognition. Experimental results in simulated learning\nscenarios demonstrate that OnlineMate effectively fosters deep learning and\ndiscussions while enhancing cognitive engagement in online educational\nsettings.","summary":"OnlineMate is a multi-agent learning companion system that enhances cognitive engagement in online learning by simulating peer-like interactions and adapting to learners' psychological states. It leverages Theory of Mind capabilities to foster deeper discussions and support cognitive development.","authors":["Xian Gao","Zongyun Zhang","Ting Liu","Yuzhuo Fu"],"categories":["cs.CY","cs.AI"],"affiliations":["Shanghai Jiao Tong University"],"keywords":["online learning","multi-agent system","cognitive support","Theory of Mind","LLM"],"language":"en","published_date":"2025-09-18T09:56:45Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14803v1"}
{"arxiv_id":"2509.14788v1","title":"Structure-Aware Contrastive Learning with Fine-Grained Binding\n  Representations for Drug Discovery","abstract":"Accurate identification of drug-target interactions (DTI) remains a central\nchallenge in computational pharmacology, where sequence-based methods offer\nscalability. This work introduces a sequence-based drug-target interaction\nframework that integrates structural priors into protein representations while\nmaintaining high-throughput screening capability. Evaluated across multiple\nbenchmarks, the model achieves state-of-the-art performance on Human and\nBioSNAP datasets and remains competitive on BindingDB. In virtual screening\ntasks, it surpasses prior methods on LIT-PCBA, yielding substantial gains in\nAUROC and BEDROC. Ablation studies confirm the critical role of learned\naggregation, bilinear attention, and contrastive alignment in enhancing\npredictive robustness. Embedding visualizations reveal improved spatial\ncorrespondence with known binding pockets and highlight interpretable attention\npatterns over ligand-residue contacts. These results validate the framework's\nutility for scalable and structure-aware DTI prediction.","summary":"This work presents a sequence-based framework for drug-target interaction prediction that integrates structural priors into protein representations. The model achieves state-of-the-art performance on multiple benchmarks while maintaining high-throughput screening capabilities.","authors":["Jing Lan","Hexiao Ding","Hongzhao Chen","Yufeng Jiang","Nga-Chun Ng","Gwing Kei Yip","Gerald W. Y. Cheng","Yunlin Mao","Jing Cai","Liang-ting Lin","Jung Sun Yoo"],"categories":["cs.LG","cs.AI","q-bio.BM"],"affiliations":["The Hong Kong Polytechnic University","Hong Kong Sanatorium and Hospital","Queen Elizabeth Hospital"],"keywords":["Drug discovery","Drug-target interactions","Attention network","Contrastive learning","Computational pharmacology"],"language":"en","published_date":"2025-09-18T09:38:46Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14788v1"}
{"arxiv_id":"2509.14778v1","title":"OpenLens AI: Fully Autonomous Research Agent for Health Infomatics","abstract":"Health informatics research is characterized by diverse data modalities,\nrapid knowledge expansion, and the need to integrate insights across biomedical\nscience, data analytics, and clinical practice. These characteristics make it\nparticularly well-suited for agent-based approaches that can automate knowledge\nexploration, manage complex workflows, and generate clinically meaningful\noutputs. Recent progress in large language model (LLM)-based agents has\ndemonstrated promising capabilities in literature synthesis, data analysis, and\neven end-to-end research execution. However, existing systems remain limited\nfor health informatics because they lack mechanisms to interpret medical\nvisualizations and often overlook domain-specific quality requirements. To\naddress these gaps, we introduce OpenLens AI, a fully automated framework\ntailored to health informatics. OpenLens AI integrates specialized agents for\nliterature review, data analysis, code generation, and manuscript preparation,\nenhanced by vision-language feedback for medical visualization and quality\ncontrol for reproducibility. The framework automates the entire research\npipeline, producing publication-ready LaTeX manuscripts with transparent and\ntraceable workflows, thereby offering a domain-adapted solution for advancing\nhealth informatics research.","summary":"OpenLens AI is a fully automated framework designed for health informatics, integrating specialized agents for various research tasks. It aims to streamline the research pipeline and produce publication-ready manuscripts while ensuring quality control.","authors":["Yuxiao Cheng","Jinli Suo"],"categories":["cs.AI","cs.MA"],"affiliations":["Tsinghua University"],"keywords":["health informatics","automated research","large language models","data analysis","workflow automation"],"language":"en","published_date":"2025-09-18T09:25:57Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14778v1"}
{"arxiv_id":"2509.14750v1","title":"Enhancing Retrieval Augmentation via Adversarial Collaboration","abstract":"Retrieval-augmented Generation (RAG) is a prevalent approach for\ndomain-specific LLMs, yet it is often plagued by \"Retrieval Hallucinations\"--a\nphenomenon where fine-tuned models fail to recognize and act upon poor-quality\nretrieved documents, thus undermining performance. To address this, we propose\nthe Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two\nheterogeneous agents: a generalist Detector that identifies knowledge gaps, and\na domain-specialized Resolver that provides precise solutions. Guided by a\nmoderator, these agents engage in an adversarial collaboration, where the\nDetector's persistent questioning challenges the Resolver's expertise. This\ndynamic process allows for iterative problem dissection and refined knowledge\nretrieval. Extensive experiments show that AC-RAG significantly improves\nretrieval accuracy and outperforms state-of-the-art RAG methods across various\nvertical domains.","summary":"The Adversarial Collaboration RAG (AC-RAG) framework improves retrieval accuracy by employing two agents that engage in adversarial collaboration to address issues like Retrieval Hallucination and Semantic Discrepancy. Extensive experiments demonstrate its superiority over existing RAG methods.","authors":["Letian Zhang","Guanghao Meng","Xudong Ren","Yiming Wang","Shu-Tao Xia"],"categories":["cs.AI"],"affiliations":["Tsinghua University","Huawei Technologies Ltd."],"keywords":["Retrieval-Augmented Generation","Adversarial Collaboration","Multi-Agent Systems","Retrieval Hallucination","Semantic Discrepancy"],"language":"en","published_date":"2025-09-18T08:54:20Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14750v1"}
{"arxiv_id":"2509.14704v1","title":"The NazoNazo Benchmark: A Cost-Effective and Extensible Test of\n  Insight-Based Reasoning in LLMs","abstract":"Benchmark saturation and contamination undermine confidence in LLM\nevaluation. We present Nazonazo, a cost-effective and extensible benchmark\nbuilt from Japanese children's riddles to test insight-based reasoning. Items\nare short (mostly one sentence), require no specialized domain knowledge, and\ncan be generated at scale, enabling rapid refresh of blind sets when leakage is\nsuspected. We evaluate 38 frontier models and 126 adults on 120 riddles. No\nmodel except for GPT-5 is comparable to human performance, which achieves a\n52.9% mean accuracy. Model comparison on extended 201 items shows that\nreasoning models significantly outperform non-reasoning peers, while model size\nshows no reliable association with accuracy. Beyond aggregate accuracy, an\ninformal candidate-tracking analysis of thought logs reveals many cases of\nverification failure: models often produce the correct solution among\nintermediate candidates yet fail to select it as the final answer, which we\nillustrate with representative examples observed in multiple models. Nazonazo\nthus offers a cost-effective, scalable, and easily renewable benchmark format\nthat addresses the current evaluation crisis while also suggesting a recurrent\nmeta-cognitive weakness, providing clear targets for future control and\ncalibration methods.","summary":"The Nazonazo Benchmark is a cost-effective tool for evaluating insight-based reasoning in LLMs using Japanese children's riddles. It highlights the limitations of current models and suggests improvements for future evaluations.","authors":["Masaharu Mizumoto","Dat Nguyen","Zhiheng Han","Jiyuan Fang","Heyuan Guan","Xingfu Li","Naoya Shiraishi","Xuyang Tian","Yo Nakawake","Le Minh Nguyen"],"categories":["cs.AI"],"affiliations":["Japan Advanced Institute of Science and Technology"],"keywords":["Insight problem solving","Large language models","Japanese children's riddles","Benchmark contamination","Metacognitive calibration"],"language":"en","published_date":"2025-09-18T07:50:04Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14704v1"}
{"arxiv_id":"2509.14693v1","title":"RationAnomaly: Log Anomaly Detection with Rationality via\n  Chain-of-Thought and Reinforcement Learning","abstract":"Logs constitute a form of evidence signaling the operational status of\nsoftware systems. Automated log anomaly detection is crucial for ensuring the\nreliability of modern software systems. However, existing approaches face\nsignificant limitations: traditional deep learning models lack interpretability\nand generalization, while methods leveraging Large Language Models are often\nhindered by unreliability and factual inaccuracies. To address these issues, we\npropose RationAnomaly, a novel framework that enhances log anomaly detection by\nsynergizing Chain-of-Thought (CoT) fine-tuning with reinforcement learning. Our\napproach first instills expert-like reasoning patterns using CoT-guided\nsupervised fine-tuning, grounded in a high-quality dataset corrected through a\nrigorous expert-driven process. Subsequently, a reinforcement learning phase\nwith a multi-faceted reward function optimizes for accuracy and logical\nconsistency, effectively mitigating hallucinations. Experimentally,\nRationAnomaly outperforms state-of-the-art baselines, achieving superior\nF1-scores on key benchmarks while providing transparent, step-by-step\nanalytical outputs. We have released the corresponding resources, including\ncode and datasets.","summary":"RationAnomaly is a novel framework that enhances log anomaly detection by combining Chain-of-Thought fine-tuning with reinforcement learning. It outperforms existing methods by achieving superior accuracy and providing transparent analytical outputs.","authors":["Song Xu","Yilun Liu","Minggui He","Mingchen Dai","Ziang Chen","Chunguang Zhao","Jingzhou Du","Shimin Tao","Weibin Meng","Shenglin Zhang","Yongqian Sun","Boxing Chen","Daimeng Wei"],"categories":["cs.AI"],"affiliations":["University of Science and Technology of China","Huawei","Nankai University"],"keywords":["Anomaly Detection","Fine-Tuning","Reinforcement Learning","Log Analysis","Large Language Model"],"language":"en","published_date":"2025-09-18T07:35:58Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14693v1"}
{"arxiv_id":"2509.14671v1","title":"TableDART: Dynamic Adaptive Multi-Modal Routing for Table Understanding","abstract":"Modeling semantic and structural information from tabular data remains a core\nchallenge for effective table understanding. Existing Table-as-Text approaches\nflatten tables for large language models (LLMs), but lose crucial structural\ncues, while Table-as-Image methods preserve structure yet struggle with\nfine-grained semantics. Recent Table-as-Multimodality strategies attempt to\ncombine textual and visual views, but they (1) statically process both\nmodalities for every query-table pair within a large multimodal LLMs (MLLMs),\ninevitably introducing redundancy and even conflicts, and (2) depend on costly\nfine-tuning of MLLMs. In light of this, we propose TableDART, a\ntraining-efficient framework that integrates multimodal views by reusing\npretrained single-modality models. TableDART introduces a lightweight\n2.59M-parameter MLP gating network that dynamically selects the optimal path\n(either Text-only, Image-only, or Fusion) for each table-query pair,\neffectively reducing redundancy and conflicts from both modalities. In\naddition, we propose a novel agent to mediate cross-modal knowledge integration\nby analyzing outputs from text- and image-based models, either selecting the\nbest result or synthesizing a new answer through reasoning. This design avoids\nthe prohibitive costs of full MLLM fine-tuning. Extensive experiments on seven\nbenchmarks show that TableDART establishes new state-of-the-art performance\namong open-source models, surpassing the strongest baseline by an average of\n4.02%. The code is available at:\nhttps:\/\/anonymous.4open.science\/r\/TableDART-C52B","summary":"TableDART is a training-efficient framework that integrates multimodal views for table understanding, reducing redundancy and conflicts. It establishes new state-of-the-art performance on seven benchmarks, surpassing existing models.","authors":["Xiaobo Xing","Wei Yuan","Tong Chen","Quoc Viet Hung Nguyen","Xiangliang Zhang","Hongzhi Yin"],"categories":["cs.CL","cs.AI","cs.LG"],"affiliations":["The University of Queensland","Griffith University","University of Notre Dame"],"keywords":["table understanding","multimodal","machine learning","dynamic routing","semantic modeling"],"language":"en","published_date":"2025-09-18T07:00:13Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14671v1"}
{"arxiv_id":"2509.14666v1","title":"Spatial Audio Motion Understanding and Reasoning","abstract":"Spatial audio reasoning enables machines to interpret auditory scenes by\nunderstanding events and their spatial attributes. In this work, we focus on\nspatial audio understanding with an emphasis on reasoning about moving sources.\nFirst, we introduce a spatial audio encoder that processes spatial audio to\ndetect multiple overlapping events and estimate their spatial attributes,\nDirection of Arrival (DoA) and source distance, at the frame level. To\ngeneralize to unseen events, we incorporate an audio grounding model that\naligns audio features with semantic audio class text embeddings via a\ncross-attention mechanism. Second, to answer complex queries about dynamic\naudio scenes involving moving sources, we condition a large language model\n(LLM) on structured spatial attributes extracted by our model. Finally, we\nintroduce a spatial audio motion understanding and reasoning benchmark dataset\nand demonstrate our framework's performance against the baseline model.","summary":"This work presents a framework for spatial audio understanding that focuses on reasoning about moving sources. It introduces a spatial audio encoder and a benchmark dataset to evaluate performance against existing models.","authors":["Arvind Krishna Sridhar","Yinyi Guo","Erik Visser"],"categories":["cs.SD","cs.AI","cs.CL"],"affiliations":["Qualcomm Technologies Inc."],"keywords":["Spatial audio","Audio reasoning","Dynamic sources","Question answering","Benchmark dataset"],"language":"en","published_date":"2025-09-18T06:53:22Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14666v1"}
{"arxiv_id":"2509.14662v1","title":"Understanding the Thinking Process of Reasoning Models: A Perspective\n  from Schoenfeld's Episode Theory","abstract":"While Large Reasoning Models (LRMs) generate extensive chain-of-thought\nreasoning, we lack a principled framework for understanding how these thoughts\nare structured. In this paper, we introduce a novel approach by applying\nSchoenfeld's Episode Theory, a classic cognitive framework for human\nmathematical problem-solving, to analyze the reasoning traces of LRMs. We\nannotated thousands of sentences and paragraphs from model-generated solutions\nto math problems using seven cognitive labels (e.g., Plan, Implement, Verify).\nThe result is the first publicly available benchmark for the fine-grained\nanalysis of machine reasoning, including a large annotated corpus and detailed\nannotation guidebooks. Our preliminary analysis reveals distinct patterns in\nLRM reasoning, such as the transition dynamics between cognitive states. This\nframework provides a theoretically grounded methodology for interpreting LRM\ncognition and enables future work on more controllable and transparent\nreasoning systems.","summary":"This paper introduces a framework using Schoenfeld’s Episode Theory to analyze the reasoning processes of Large Reasoning Models. It provides a benchmark for understanding LRM cognition through annotated reasoning traces.","authors":["Ming Li","Nan Zhang","Chenrui Fan","Hong Jiao","Yanbin Fu","Sydney Peters","Qingshu Xu","Robert Lissitz","Tianyi Zhou"],"categories":["cs.AI","cs.CL","cs.LG"],"affiliations":["University of Maryland"],"keywords":["Large Reasoning Models","Schoenfeld's Episode Theory","cognitive analysis","machine reasoning","problem-solving"],"language":"en","published_date":"2025-09-18T06:42:41Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14662v1"}
{"arxiv_id":"2509.14657v1","title":"Threat Modeling for Enhancing Security of IoT Audio Classification\n  Devices under a Secure Protocols Framework","abstract":"The rapid proliferation of IoT nodes equipped with microphones and capable of\nperforming on-device audio classification exposes highly sensitive data while\noperating under tight resource constraints. To protect against this, we present\na defence-in-depth architecture comprising a security protocol that treats the\nedge device, cellular network and cloud backend as three separate trust\ndomains, linked by TPM-based remote attestation and mutually authenticated TLS\n1.3. A STRIDE-driven threat model and attack-tree analysis guide the design. At\nstartup, each boot stage is measured into TPM PCRs. The node can only decrypt\nits LUKS-sealed partitions after the cloud has verified a TPM quote and\nreleased a one-time unlock key. This ensures that rogue or tampered devices\nremain inert. Data in transit is protected by TLS 1.3 and hybridised with Kyber\nand Dilithium to provide post-quantum resilience. Meanwhile, end-to-end\nencryption and integrity hashes safeguard extracted audio features. Signed,\nrollback-protected AI models and tamper-responsive sensors harden firmware and\nhardware. Data at rest follows a 3-2-1 strategy comprising a solid-state drive\nsealed with LUKS, an offline cold archive encrypted with a hybrid post-quantum\ncipher and an encrypted cloud replica. Finally, we set out a plan for\nevaluating the physical and logical security of the proposed protocol.","summary":"This paper presents a defense-in-depth architecture for securing IoT audio classification devices through a multi-domain security protocol. It employs a STRIDE-driven threat model and post-quantum encryption to protect sensitive data and ensure device integrity.","authors":["Sergio Benlloch-Lopez","Miquel Viel-Vazquez","Javier Naranjo-Alcazar","Jordi Grau-Haro","Pedro Zuccarello"],"categories":["cs.CR","cs.AI"],"affiliations":["Instituto Tecnologico de Informatica"],"keywords":["IoT","security","audio classification","threat modeling","encryption"],"language":"en","published_date":"2025-09-18T06:25:50Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14657v1"}
{"arxiv_id":"2509.14651v1","title":"MUSE: MCTS-Driven Red Teaming Framework for Enhanced Multi-Turn Dialogue\n  Safety in Large Language Models","abstract":"As large language models~(LLMs) become widely adopted, ensuring their\nalignment with human values is crucial to prevent jailbreaks where adversaries\nmanipulate models to produce harmful content. While most defenses target\nsingle-turn attacks, real-world usage often involves multi-turn dialogues,\nexposing models to attacks that exploit conversational context to bypass safety\nmeasures. We introduce MUSE, a comprehensive framework tackling multi-turn\njailbreaks from both attack and defense angles. For attacks, we propose MUSE-A,\na method that uses frame semantics and heuristic tree search to explore diverse\nsemantic trajectories. For defense, we present MUSE-D, a fine-grained safety\nalignment approach that intervenes early in dialogues to reduce\nvulnerabilities. Extensive experiments on various models show that MUSE\neffectively identifies and mitigates multi-turn vulnerabilities. Code is\navailable at\n\\href{https:\/\/github.com\/yansiyu02\/MUSE}{https:\/\/github.com\/yansiyu02\/MUSE}.","summary":"The paper introduces MUSE, a framework designed to address multi-turn jailbreaks in large language models by exploring attack and defense strategies. It emphasizes the importance of aligning models with human values to prevent harmful content generation.","authors":["Siyu Yan","Long Zeng","Xuecheng Wu","Chengcheng Han","Kongcheng Zhang","Chong Peng","Xuezhi Cao","Xunliang Cai","Chenjuan Guo"],"categories":["cs.CL","cs.AI"],"affiliations":["East China Normal University","Xi’an Jiaotong University","Meituan","Zhejiang University"],"keywords":["large language models","multi-turn dialogue","safety alignment","jailbreaks","semantic trajectories"],"language":"en","published_date":"2025-09-18T06:12:27Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14651v1"}
{"arxiv_id":"2509.14647v1","title":"AgentCompass: Towards Reliable Evaluation of Agentic Workflows in\n  Production","abstract":"With the growing adoption of Large Language Models (LLMs) in automating\ncomplex, multi-agent workflows, organizations face mounting risks from errors,\nemergent behaviors, and systemic failures that current evaluation methods fail\nto capture. We present AgentCompass, the first evaluation framework designed\nspecifically for post-deployment monitoring and debugging of agentic workflows.\nAgentCompass models the reasoning process of expert debuggers through a\nstructured, multi-stage analytical pipeline: error identification and\ncategorization, thematic clustering, quantitative scoring, and strategic\nsummarization. The framework is further enhanced with a dual memory\nsystem-episodic and semantic-that enables continual learning across executions.\nThrough collaborations with design partners, we demonstrate the framework's\npractical utility on real-world deployments, before establishing its efficacy\nagainst the publicly available TRAIL benchmark. AgentCompass achieves\nstate-of-the-art results on key metrics, while uncovering critical issues\nmissed in human annotations, underscoring its role as a robust,\ndeveloper-centric tool for reliable monitoring and improvement of agentic\nsystems in production.","summary":"AgentCompass is an evaluation framework designed for post-deployment monitoring and debugging of agentic workflows. It enhances error identification and learning through a dual memory system, achieving state-of-the-art results in real-world applications.","authors":["NVJK Kartik","Garvit Sapra","Rishav Hada","Nikhil Pareek"],"categories":["cs.AI","cs.CL"],"affiliations":["FutureAGI Inc."],"keywords":["AgentCompass","evaluation framework","agentic workflows","Large Language Models","monitoring"],"language":"en","published_date":"2025-09-18T05:59:04Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14647v1"}
{"arxiv_id":"2509.14642v1","title":"DeCoP: Enhancing Self-Supervised Time Series Representation with\n  Dependency Controlled Pre-training","abstract":"Modeling dynamic temporal dependencies is a critical challenge in time series\npre-training, which evolve due to distribution shifts and multi-scale patterns.\nThis temporal variability severely impairs the generalization of pre-trained\nmodels to downstream tasks. Existing frameworks fail to capture the complex\ninteractions of short- and long-term dependencies, making them susceptible to\nspurious correlations that degrade generalization. To address these\nlimitations, we propose DeCoP, a Dependency Controlled Pre-training framework\nthat explicitly models dynamic, multi-scale dependencies by simulating evolving\ninter-patch dependencies. At the input level, DeCoP introduces Instance-wise\nPatch Normalization (IPN) to mitigate distributional shifts while preserving\nthe unique characteristics of each patch, creating a robust foundation for\nrepresentation learning. At the latent level, a hierarchical Dependency\nControlled Learning (DCL) strategy explicitly models inter-patch dependencies\nacross multiple temporal scales, with an Instance-level Contrastive Module\n(ICM) enhances global generalization by learning instance-discriminative\nrepresentations from time-invariant positive pairs. DeCoP achieves\nstate-of-the-art results on ten datasets with lower computing resources,\nimproving MSE by 3% on ETTh1 over PatchTST using only 37% of the FLOPs.","summary":"DeCoP is a framework that enhances self-supervised time series representation by modeling dynamic, multi-scale dependencies. It addresses challenges in generalization and distribution shifts, achieving state-of-the-art results with lower computational resources.","authors":["Yuemin Wu","Zhongze Wu","Xiu Su","Feng Yang","Hongyan Xu","Xi Lin","Wenti Huang","Shan You","Chang Xu"],"categories":["cs.LG","cs.AI"],"affiliations":["USYD","CSU","SEU","SJTU","HNUST","SenseTime Research"],"keywords":["time series","self-supervised learning","pre-training","dependency modeling","generalization"],"language":"en","published_date":"2025-09-18T05:44:06Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14642v1"}
{"arxiv_id":"2509.14632v1","title":"Mitigating Intra-Speaker Variability in Diarization with\n  Style-Controllable Speech Augmentation","abstract":"Speaker diarization systems often struggle with high intrinsic intra-speaker\nvariability, such as shifts in emotion, health, or content. This can cause\nsegments from the same speaker to be misclassified as different individuals,\nfor example, when one raises their voice or speaks faster during conversation.\nTo address this, we propose a style-controllable speech generation model that\naugments speech across diverse styles while preserving the target speaker's\nidentity. The proposed system starts with diarized segments from a conventional\ndiarizer. For each diarized segment, it generates augmented speech samples\nenriched with phonetic and stylistic diversity. And then, speaker embeddings\nfrom both the original and generated audio are blended to enhance the system's\nrobustness in grouping segments with high intrinsic intra-speaker variability.\nWe validate our approach on a simulated emotional speech dataset and the\ntruncated AMI dataset, demonstrating significant improvements, with error rate\nreductions of 49% and 35% on each dataset, respectively.","summary":"This work proposes a style-controllable speech generation model to mitigate intra-speaker variability in speaker diarization systems. The approach enhances robustness by generating augmented speech samples while preserving the target speaker's identity.","authors":["Miseul Kim","Soo Jin Park","Kyungguen Byun","Hyeon-Kyeong Shin","Sunkuk Moon","Shuhua Zhang","Erik Visser"],"categories":["eess.AS","cs.AI","eess.SP"],"affiliations":["Yonsei University","Qualcomm Technologies, Inc."],"keywords":["Speaker diarization","Speech generation","Data augmentation","Intrinsic variability","Style control"],"language":"en","published_date":"2025-09-18T05:21:20Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14632v1"}
{"arxiv_id":"2509.14627v1","title":"Towards Human-like Multimodal Conversational Agent by Generating\n  Engaging Speech","abstract":"Human conversation involves language, speech, and visual cues, with each\nmedium providing complementary information. For instance, speech conveys a vibe\nor tone not fully captured by text alone. While multimodal LLMs focus on\ngenerating text responses from diverse inputs, less attention has been paid to\ngenerating natural and engaging speech. We propose a human-like agent that\ngenerates speech responses based on conversation mood and responsive style\ninformation. To achieve this, we build a novel MultiSensory Conversation\ndataset focused on speech to enable agents to generate natural speech. We then\npropose a multimodal LLM-based model for generating text responses and voice\ndescriptions, which are used to generate speech covering paralinguistic\ninformation. Experimental results demonstrate the effectiveness of utilizing\nboth visual and audio modalities in conversation to generate engaging speech.\nThe source code is available in https:\/\/github.com\/kimtaesu24\/MSenC","summary":"This work proposes a human-like conversational agent that generates engaging speech responses by utilizing multimodal inputs. A new dataset, MultiSensory Conversation, is introduced to enhance the training of such agents.","authors":["Taesoo Kim","Yongsik Jo","Hyunmin Song","Taehwan Kim"],"categories":["cs.HC","cs.AI","cs.CL"],"affiliations":["UNIST"],"keywords":["multimodal","conversational agent","speech generation","paralinguistics","dataset"],"language":"en","published_date":"2025-09-18T05:14:10Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14627v1"}
{"arxiv_id":"2509.14624v1","title":"Reveal and Release: Iterative LLM Unlearning with Self-generated Data","abstract":"Large language model (LLM) unlearning has demonstrated effectiveness in\nremoving the influence of undesirable data (also known as forget data).\nExisting approaches typically assume full access to the forget dataset,\noverlooking two key challenges: (1) Forget data is often privacy-sensitive,\nrare, or legally regulated, making it expensive or impractical to obtain (2)\nThe distribution of available forget data may not align with how that\ninformation is represented within the model. To address these limitations, we\npropose a ``Reveal-and-Release'' method to unlearn with self-generated data,\nwhere we prompt the model to reveal what it knows using optimized instructions.\nTo fully utilize the self-generated forget data, we propose an iterative\nunlearning framework, where we make incremental adjustments to the model's\nweight space with parameter-efficient modules trained on the forget data.\nExperimental results demonstrate that our method balances the tradeoff between\nforget quality and utility preservation.","summary":"This paper proposes a 'Reveal-and-Release' method for LLM unlearning using self-generated data to address challenges related to privacy-sensitive forget data. An iterative unlearning framework is introduced to balance forget quality and utility preservation.","authors":["Linxi Xie","Xin Teng","Shichang Ke","Hongyi Wen","Shengjie Wang"],"categories":["cs.CL","cs.AI","cs.LG"],"affiliations":["New York University Shanghai","Center for Data Science"],"keywords":["LLM unlearning","self-generated data","privacy-sensitive data","iterative unlearning","model performance"],"language":"en","published_date":"2025-09-18T05:07:27Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14624v1"}
{"arxiv_id":"2509.14623v1","title":"Automating Modelica Module Generation Using Large Language Models: A\n  Case Study on Building Control Description Language","abstract":"Dynamic energy systems and controls require advanced modeling frameworks to\ndesign and test supervisory and fault tolerant strategies. Modelica is a widely\nused equation based language, but developing control modules is labor intensive\nand requires specialized expertise. This paper examines the use of large\nlanguage models (LLMs) to automate the generation of Control Description\nLanguage modules in the Building Modelica Library as a case study. We developed\na structured workflow that combines standardized prompt scaffolds, library\naware grounding, automated compilation with OpenModelica, and human in the loop\nevaluation. Experiments were carried out on four basic logic tasks (And, Or,\nNot, and Switch) and five control modules (chiller enable\/disable, bypass valve\ncontrol, cooling tower fan speed, plant requests, and relief damper control).\nThe results showed that GPT 4o failed to produce executable Modelica code in\nzero shot mode, while Claude Sonnet 4 achieved up to full success for basic\nlogic blocks with carefully engineered prompts. For control modules, success\nrates reached 83 percent, and failed outputs required medium level human repair\n(estimated one to eight hours). Retrieval augmented generation often produced\nmismatches in module selection (for example, And retrieved as Or), while a\ndeterministic hard rule search strategy avoided these errors. Human evaluation\nalso outperformed AI evaluation, since current LLMs cannot assess simulation\nresults or validate behavioral correctness. Despite these limitations, the LLM\nassisted workflow reduced the average development time from 10 to 20 hours down\nto 4 to 6 hours per module, corresponding to 40 to 60 percent time savings.\nThese results highlight both the potential and current limitations of LLM\nassisted Modelica generation, and point to future research in pre simulation\nvalidation, stronger grounding, and closed loop evaluation.","summary":"This study explores the automation of Modelica module generation using large language models, focusing on building control description language. The research is supported by the U.S. Department of Energy and Battelle Memorial Institute.","authors":["Hanlong Wan","Xing Lu","Yan Chen","Karthik Devaprasad","Laura Hinkle"],"categories":["cs.SE","cs.AI","cs.PL","cs.SY","eess.SY"],"affiliations":["Pacific Northwest National Laboratory","Battelle Memorial Institute"],"keywords":["Modelica","Automation","Large Language Models","Building Control","Research"],"language":"en","published_date":"2025-09-18T05:07:17Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14623v1"}
{"arxiv_id":"2509.14622v1","title":"Adversarial Distilled Retrieval-Augmented Guarding Model for Online\n  Malicious Intent Detection","abstract":"With the deployment of Large Language Models (LLMs) in interactive\napplications, online malicious intent detection has become increasingly\ncritical. However, existing approaches fall short of handling diverse and\ncomplex user queries in real time. To address these challenges, we introduce\nADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework\nfor robust and efficient online malicious intent detection. In the training\nstage, a high-capacity teacher model is trained on adversarially perturbed,\nretrieval-augmented inputs to learn robust decision boundaries over diverse and\ncomplex user queries. In the inference stage, a distillation scheduler\ntransfers the teacher's knowledge into a compact student model, with a\ncontinually updated knowledge base collected online. At deployment, the compact\nstudent model leverages top-K similar safety exemplars retrieved from the\nonline-updated knowledge base to enable both online and real-time malicious\nquery detection. Evaluations across ten safety benchmarks demonstrate that\nADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's\nperformance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on\nout-of-distribution detection, while simultaneously delivering up to 5.6x lower\nlatency at 300 queries per second (QPS) in real-time applications.","summary":"The paper introduces ADRAG, a two-stage framework for online malicious intent detection using large language models. It demonstrates improved performance and lower latency compared to existing methods.","authors":["Yihao Guo","Haocheng Bian","Liutong Zhou","Ze Wang","Zhaoyi Zhang","Francois Kawala","Milan Dean","Ian Fischer","Yuantao Peng","Noyan Tokgozoglu","Ivan Barrientos","Riyaaz Shaik","Rachel Li","Chandru Venkataraman","Reza Shifteh Far","Moses Pawar","Venkat Sundaranatha","Michael Xu","Frank Chu"],"categories":["cs.CR","cs.AI","cs.LG"],"affiliations":["Apple","Cohere","DeepMind","Meta","MongoDB"],"keywords":["malicious intent detection","large language models","adversarial training","real-time applications","retrieval-augmented"],"language":"en","published_date":"2025-09-18T05:04:48Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14622v1"}
{"arxiv_id":"2509.14619v1","title":"LSTC-MDA: A Unified Framework for Long-Short Term Temporal Convolution\n  and Mixed Data Augmentation in Skeleton-Based Action Recognition","abstract":"Skeleton-based action recognition faces two longstanding challenges: the\nscarcity of labeled training samples and difficulty modeling short- and\nlong-range temporal dependencies. To address these issues, we propose a unified\nframework, LSTC-MDA, which simultaneously improves temporal modeling and data\ndiversity. We introduce a novel Long-Short Term Temporal Convolution (LSTC)\nmodule with parallel short- and long-term branches, these two feature branches\nare then aligned and fused adaptively using learned similarity weights to\npreserve critical long-range cues lost by conventional stride-2 temporal\nconvolutions. We also extend Joint Mixing Data Augmentation (JMDA) with an\nAdditive Mixup at the input level, diversifying training samples and\nrestricting mixup operations to the same camera view to avoid distribution\nshifts. Ablation studies confirm each component contributes. LSTC-MDA achieves\nstate-of-the-art results: 94.1% and 97.5% on NTU 60 (X-Sub and X-View), 90.4%\nand 92.0% on NTU 120 (X-Sub and X-Set),97.2% on NW-UCLA. Code:\nhttps:\/\/github.com\/xiaobaoxia\/LSTC-MDA.","summary":"The paper presents LSTC-MDA, a framework that enhances skeleton-based action recognition by improving temporal modeling and data diversity. It achieves state-of-the-art results on multiple benchmarks while addressing challenges related to labeled data scarcity and temporal dependencies.","authors":["Feng Ding","Haisheng Fu","Soroush Oraki","Jie Liang"],"categories":["cs.CV","cs.AI"],"affiliations":["Simon Fraser University"],"keywords":["Skeleton-based Action Recognition","Temporal Convolution","Data Augmentation","Long-Short Term","Machine Learning"],"language":"en","published_date":"2025-09-18T04:48:32Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14619v1"}
{"arxiv_id":"2509.14608v1","title":"Enterprise AI Must Enforce Participant-Aware Access Control","abstract":"Large language models (LLMs) are increasingly deployed in enterprise settings\nwhere they interact with multiple users and are trained or fine-tuned on\nsensitive internal data. While fine-tuning enhances performance by\ninternalizing domain knowledge, it also introduces a critical security risk:\nleakage of confidential training data to unauthorized users. These risks are\nexacerbated when LLMs are combined with Retrieval-Augmented Generation (RAG)\npipelines that dynamically fetch contextual documents at inference time.\n  We demonstrate data exfiltration attacks on AI assistants where adversaries\ncan exploit current fine-tuning and RAG architectures to leak sensitive\ninformation by leveraging the lack of access control enforcement. We show that\nexisting defenses, including prompt sanitization, output filtering, system\nisolation, and training-level privacy mechanisms, are fundamentally\nprobabilistic and fail to offer robust protection against such attacks.\n  We take the position that only a deterministic and rigorous enforcement of\nfine-grained access control during both fine-tuning and RAG-based inference can\nreliably prevent the leakage of sensitive data to unauthorized recipients.\n  We introduce a framework centered on the principle that any content used in\ntraining, retrieval, or generation by an LLM is explicitly authorized for\n\\emph{all users involved in the interaction}. Our approach offers a simple yet\npowerful paradigm shift for building secure multi-user LLM systems that are\ngrounded in classical access control but adapted to the unique challenges of\nmodern AI workflows. Our solution has been deployed in Microsoft Copilot\nTuning, a product offering that enables organizations to fine-tune models using\ntheir own enterprise-specific data.","summary":"This paper discusses the security risks associated with fine-tuning large language models in enterprise settings, particularly the potential for data leakage. It proposes a framework for enforcing rigorous access control to prevent unauthorized data access.","authors":["Shashank Shreedhar Bhatt","Tanmay Rajore","Khushboo Aggarwal","Ganesh Ananthanarayanan","Ranveer Chandra","Nishanth Chandran","Suyash Choudhury","Divya Gupta","Emre Kiciman","Sumit Kumar Pandey","Srinath Setty","Rahul Sharma","Teijia Zhao"],"categories":["cs.CR","cs.AI"],"affiliations":["Microsoft Corporation"],"keywords":["enterprise AI","access control","data leakage","large language models","security"],"language":"en","published_date":"2025-09-18T04:30:49Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14608v1"}
{"arxiv_id":"2509.14601v1","title":"A Case for Computing on Unstructured Data","abstract":"Unstructured data, such as text, images, audio, and video, comprises the vast\nmajority of the world's information, yet it remains poorly supported by\ntraditional data systems that rely on structured formats for computation. We\nargue for a new paradigm, which we call computing on unstructured data, built\naround three stages: extraction of latent structure, transformation of this\nstructure through data processing techniques, and projection back into\nunstructured formats. This bi-directional pipeline allows unstructured data to\nbenefit from the analytical power of structured computation, while preserving\nthe richness and accessibility of unstructured representations for human and AI\nconsumption. We illustrate this paradigm through two use cases and present the\nresearch components that need to be developed in a new data system called\nMXFlow.","summary":"This paper proposes a new paradigm for computing on unstructured data, emphasizing a bi-directional XTP pipeline that enhances data processing. It aims to integrate structured computation with the richness of unstructured formats for improved human and AI interaction.","authors":["Mushtari Sadia","Amrita Roy Chowdhury","Ang Chen"],"categories":["cs.DB","cs.AI"],"affiliations":["University of Michigan"],"keywords":["unstructured data","computing","XTP pipeline","data processing","AI"],"language":"en","published_date":"2025-09-18T04:24:41Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14601v1"}
{"arxiv_id":"2509.14594v1","title":"SynBench: A Benchmark for Differentially Private Text Generation","abstract":"Data-driven decision support in high-stakes domains like healthcare and\nfinance faces significant barriers to data sharing due to regulatory,\ninstitutional, and privacy concerns. While recent generative AI models, such as\nlarge language models, have shown impressive performance in open-domain tasks,\ntheir adoption in sensitive environments remains limited by unpredictable\nbehaviors and insufficient privacy-preserving datasets for benchmarking.\nExisting anonymization methods are often inadequate, especially for\nunstructured text, as redaction and masking can still allow re-identification.\nDifferential Privacy (DP) offers a principled alternative, enabling the\ngeneration of synthetic data with formal privacy assurances. In this work, we\naddress these challenges through three key contributions. First, we introduce a\ncomprehensive evaluation framework with standardized utility and fidelity\nmetrics, encompassing nine curated datasets that capture domain-specific\ncomplexities such as technical jargon, long-context dependencies, and\nspecialized document structures. Second, we conduct a large-scale empirical\nstudy benchmarking state-of-the-art DP text generation methods and LLMs of\nvarying sizes and different fine-tuning strategies, revealing that high-quality\ndomain-specific synthetic data generation under DP constraints remains an\nunsolved challenge, with performance degrading as domain complexity increases.\nThird, we develop a membership inference attack (MIA) methodology tailored for\nsynthetic text, providing first empirical evidence that the use of public\ndatasets - potentially present in pre-training corpora - can invalidate claimed\nprivacy guarantees. Our findings underscore the urgent need for rigorous\nprivacy auditing and highlight persistent gaps between open-domain and\nspecialist evaluations, informing responsible deployment of generative AI in\nprivacy-sensitive, high-stakes settings.","summary":"This work introduces a framework for evaluating Differential Privacy in text generation, addressing challenges in data sharing for sensitive domains. It highlights the need for rigorous privacy auditing and the gaps in current methodologies.","authors":["Yidan Sun","Viktor Schlegel","Srinivasan Nandakumar","Iqra Zahid","Yuping Wu","Yulong Wu","Hao Li","Jie Zhang","Warren Del-Pinto","Goran Nenadic","Siew Kei Lam","Anil Anthony Bharath"],"categories":["cs.AI"],"affiliations":["Imperial College London","University of Manchester","Agency for Science, Technology and Research (A*STAR)","Nanyang Technological University"],"keywords":["Differential Privacy","Text Generation","Synthetic Data","Privacy Auditing","Generative AI"],"language":"en","published_date":"2025-09-18T03:57:50Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14594v1"}
{"arxiv_id":"2509.14589v1","title":"ATLANTIS: AI-driven Threat Localization, Analysis, and Triage\n  Intelligence System","abstract":"We present ATLANTIS, the cyber reasoning system developed by Team Atlanta\nthat won 1st place in the Final Competition of DARPA's AI Cyber Challenge\n(AIxCC) at DEF CON 33 (August 2025). AIxCC (2023-2025) challenged teams to\nbuild autonomous cyber reasoning systems capable of discovering and patching\nvulnerabilities at the speed and scale of modern software. ATLANTIS integrates\nlarge language models (LLMs) with program analysis -- combining symbolic\nexecution, directed fuzzing, and static analysis -- to address limitations in\nautomated vulnerability discovery and program repair. Developed by researchers\nat Georgia Institute of Technology, Samsung Research, KAIST, and POSTECH, the\nsystem addresses core challenges: scaling across diverse codebases from C to\nJava, achieving high precision while maintaining broad coverage, and producing\nsemantically correct patches that preserve intended behavior. We detail the\ndesign philosophy, architectural decisions, and implementation strategies\nbehind ATLANTIS, share lessons learned from pushing the boundaries of automated\nsecurity when program analysis meets modern AI, and release artifacts to\nsupport reproducibility and future research.","summary":"The paper presents ATLANTIS, an AI-driven system for threat localization, analysis, and triage. It aims to enhance intelligence operations through advanced technology.","authors":["Taesoo Kim","HyungSeok Han","Soyeon Park","Dae R. Jeong","Dohyeok Kim","Dongkwan Kim","Eunsoo Kim","Jiho Kim","Joshua Wang","Kangsu Kim","Sangwoo Ji","Woosun Song","Hanqing Zhao","Andrew Chin","Gyejin Lee","Kevin Stevens","Mansour Alharthi","Yizhuo Zhai","Cen Zhang","Joonun Jang","Yeongjin Jang","Ammar Askar","Dongju Kim","Fabian Fleischer","Jeongin Cho","Junsik Kim","Kyungjoon Ko","Insu Yun","Sangdon Park","Dowoo Baik","Haein Lee","Hyeon Heo","Minjae Gwon","Minjae Lee","Minwoo Baek","Seunggi Min","Wonyoung Kim","Yonghwi Jin","Younggi Park","Yunjae Choi","Jinho Jung","Gwanhyun Lee","Junyoung Jang","Kyuheon Kim","Yeonghyeon Cha","Youngjoon Kim"],"categories":["cs.CR","cs.AI"],"affiliations":[],"keywords":["AI","threat localization","analysis","triage","intelligence system"],"language":"en","published_date":"2025-09-18T03:46:18Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14589v1"}
{"arxiv_id":"2509.14581v1","title":"Can I Trust This Chatbot? Assessing User Privacy in AI-Healthcare\n  Chatbot Applications","abstract":"As Conversational Artificial Intelligence (AI) becomes more integrated into\neveryday life, AI-powered chatbot mobile applications are increasingly adopted\nacross industries, particularly in the healthcare domain. These chatbots offer\naccessible and 24\/7 support, yet their collection and processing of sensitive\nhealth data present critical privacy concerns. While prior research has\nexamined chatbot security, privacy issues specific to AI healthcare chatbots\nhave received limited attention. Our study evaluates the privacy practices of\n12 widely downloaded AI healthcare chatbot apps available on the App Store and\nGoogle Play in the United States. We conducted a three-step assessment\nanalyzing: (1) privacy settings during sign-up, (2) in-app privacy controls,\nand (3) the content of privacy policies. The analysis identified significant\ngaps in user data protection. Our findings reveal that half of the examined\napps did not present a privacy policy during sign up, and only two provided an\noption to disable data sharing at that stage. The majority of apps' privacy\npolicies failed to address data protection measures. Moreover, users had\nminimal control over their personal data. The study provides key insights for\ninformation science researchers, developers, and policymakers to improve\nprivacy protections in AI healthcare chatbot apps.","summary":"This study evaluates the privacy practices of AI healthcare chatbots, revealing significant gaps in user data protection and privacy policy transparency. It highlights the need for improved privacy safeguards in chatbot applications.","authors":["Ramazan Yener","Guan-Hung Chen","Ece Gumusel","Masooda Bashir"],"categories":["cs.HC","cs.AI","cs.CY","cs.ET"],"affiliations":["University of Illinois Urbana-Champaign","Indiana University Bloomington"],"keywords":["AI Healthcare Chatbots","User Privacy","Data Protection","Privacy Policies","Information Science"],"language":"en","published_date":"2025-09-18T03:29:43Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14581v1"}
{"arxiv_id":"2509.14574v1","title":"Do Vision-Language Models See Urban Scenes as People Do? An Urban\n  Perception Benchmark","abstract":"Understanding how people read city scenes can inform design and planning. We\nintroduce a small benchmark for testing vision-language models (VLMs) on urban\nperception using 100 Montreal street images, evenly split between photographs\nand photorealistic synthetic scenes. Twelve participants from seven community\ngroups supplied 230 annotation forms across 30 dimensions mixing physical\nattributes and subjective impressions. French responses were normalized to\nEnglish. We evaluated seven VLMs in a zero-shot setup with a structured prompt\nand deterministic parser. We use accuracy for single-choice items and Jaccard\noverlap for multi-label items; human agreement uses Krippendorff's alpha and\npairwise Jaccard. Results suggest stronger model alignment on visible,\nobjective properties than subjective appraisals. The top system (claude-sonnet)\nreaches macro 0.31 and mean Jaccard 0.48 on multi-label items. Higher human\nagreement coincides with better model scores. Synthetic images slightly lower\nscores. We release the benchmark, prompts, and harness for reproducible,\nuncertainty-aware evaluation in participatory urban analysis.","summary":"This study introduces a benchmark for evaluating vision-language models on urban perception using Montreal street images. Results indicate that models align better with objective properties than subjective appraisals.","authors":["Rashid Mushkani"],"categories":["cs.CV","cs.AI"],"affiliations":["Université de Montréal","Mila – Quebec AI Institute"],"keywords":["vision-language models","urban perception","street-level imagery","human-AI alignment","participatory methods"],"language":"en","published_date":"2025-09-18T03:21:10Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14574v1"}
{"arxiv_id":"2509.14571v1","title":"VisMoDAl: Visual Analytics for Evaluating and Improving Corruption\n  Robustness of Vision-Language Models","abstract":"Vision-language (VL) models have shown transformative potential across\nvarious critical domains due to their capability to comprehend multi-modal\ninformation. However, their performance frequently degrades under distribution\nshifts, making it crucial to assess and improve robustness against real-world\ndata corruption encountered in practical applications. While advancements in VL\nbenchmark datasets and data augmentation (DA) have contributed to robustness\nevaluation and improvement, there remain challenges due to a lack of in-depth\ncomprehension of model behavior as well as the need for expertise and iterative\nefforts to explore data patterns. Given the achievement of visualization in\nexplaining complex models and exploring large-scale data, understanding the\nimpact of various data corruption on VL models aligns naturally with a visual\nanalytics approach. To address these challenges, we introduce VisMoDAl, a\nvisual analytics framework designed to evaluate VL model robustness against\nvarious corruption types and identify underperformed samples to guide the\ndevelopment of effective DA strategies. Grounded in the literature review and\nexpert discussions, VisMoDAl supports multi-level analysis, ranging from\nexamining performance under specific corruptions to task-driven inspection of\nmodel behavior and corresponding data slice. Unlike conventional works,\nVisMoDAl enables users to reason about the effects of corruption on VL models,\nfacilitating both model behavior understanding and DA strategy formulation. The\nutility of our system is demonstrated through case studies and quantitative\nevaluations focused on corruption robustness in the image captioning task.","summary":"This paper introduces VisMoDAl, a visual analytics framework for evaluating the robustness of vision-language models against data corruption. It aims to enhance understanding of model behavior and guide effective data augmentation strategies.","authors":["Huanchen Wang","Wencheng Zhang","Zhiqiang Wang","Zhicong Lu","Yuxin Ma"],"categories":["cs.HC","cs.AI","cs.LG"],"affiliations":["Southern University of Science and Technology","City University of Hong Kong","George Mason University"],"keywords":["visual analytics","multi-modal model","corruption robustness","image captioning"],"language":"en","published_date":"2025-09-18T03:15:00Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14571v1"}
{"arxiv_id":"2509.14558v1","title":"LLM Jailbreak Detection for (Almost) Free!","abstract":"Large language models (LLMs) enhance security through alignment when widely\nused, but remain susceptible to jailbreak attacks capable of producing\ninappropriate content. Jailbreak detection methods show promise in mitigating\njailbreak attacks through the assistance of other models or multiple model\ninferences. However, existing methods entail significant computational costs.\nIn this paper, we first present a finding that the difference in output\ndistributions between jailbreak and benign prompts can be employed for\ndetecting jailbreak prompts. Based on this finding, we propose a Free Jailbreak\nDetection (FJD) which prepends an affirmative instruction to the input and\nscales the logits by temperature to further distinguish between jailbreak and\nbenign prompts through the confidence of the first token. Furthermore, we\nenhance the detection performance of FJD through the integration of virtual\ninstruction learning. Extensive experiments on aligned LLMs show that our FJD\ncan effectively detect jailbreak prompts with almost no additional\ncomputational costs during LLM inference.","summary":"This paper presents a Free Jailbreak Detection (FJD) method that utilizes output distribution differences to detect jailbreak prompts with minimal computational costs. The approach enhances detection performance through virtual instruction learning.","authors":["Guorui Chen","Yifan Xia","Xiaojun Jia","Zhijiang Li","Philip Torr","Jindong Gu"],"categories":["cs.CR","cs.AI","cs.CL"],"affiliations":["Wuhan University","Nanyang Technological University","University of Oxford"],"keywords":["jailbreak detection","large language models","computational costs","security","alignment"],"language":"en","published_date":"2025-09-18T02:42:52Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14558v1"}
{"arxiv_id":"2509.14547v1","title":"(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via\n  Multi-Agent Collaboration","abstract":"Recent studies have shown that carefully designed workflows coordinating\nlarge language models(LLMs) significantly enhance task-solving capabilities\ncompared to using a single model. While an increasing number of works focus on\nautonomous workflow construction, most existing approaches rely solely on\nhistorical experience, leading to limitations in efficiency and adaptability.\nWe argue that while historical experience is valuable, workflow construction\nshould also flexibly respond to the unique characteristics of each task. To\nthis end, we propose an a priori dynamic framework for automated workflow\nconstruction. Our framework first leverages Q-table learning to optimize the\ndecision space, guiding agent decisions and enabling effective use of\nhistorical experience. At the same time, agents evaluate the current task\nprogress and make a priori decisions regarding the next executing agent,\nallowing the system to proactively select the more suitable workflow structure\nfor each given task. Additionally, we incorporate mechanisms such as cold-start\ninitialization, early stopping, and pruning to further improve system\nefficiency. Experimental evaluations on four benchmark datasets demonstrate the\nfeasibility and effectiveness of our approach. Compared to state-of-the-art\nbaselines, our method achieves an average improvement of 4.05%, while reducing\nworkflow construction and inference costs to only 30.68%-48.31% of those\nrequired by existing methods.","summary":"This paper proposes a dynamic framework for automated workflow construction using multi-agent collaboration, enhancing efficiency and adaptability. Experimental results show significant improvements over existing methods.","authors":["Yi Lin","Lujin Zhao","Yijie Shi"],"categories":["cs.AI"],"affiliations":["Beijing University of Posts and Telecommunications"],"keywords":["dynamic workflow","multi-agent systems","large language models","automated construction","Q-learning"],"language":"en","published_date":"2025-09-18T02:24:14Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14547v1"}
{"arxiv_id":"2509.14546v1","title":"Rationality Check! Benchmarking the Rationality of Large Language Models","abstract":"Large language models (LLMs), a recent advance in deep learning and machine\nintelligence, have manifested astonishing capacities, now considered among the\nmost promising for artificial general intelligence. With human-like\ncapabilities, LLMs have been used to simulate humans and serve as AI assistants\nacross many applications. As a result, great concern has arisen about whether\nand under what circumstances LLMs think and behave like real human agents.\nRationality is among the most important concepts in assessing human behavior,\nboth in thinking (i.e., theoretical rationality) and in taking action (i.e.,\npractical rationality). In this work, we propose the first benchmark for\nevaluating the omnibus rationality of LLMs, covering a wide range of domains\nand LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental\nresults, and analysis that illuminates where LLMs converge and diverge from\nidealized human rationality. We believe the benchmark can serve as a\nfoundational tool for both developers and users of LLMs.","summary":"This paper proposes a benchmark for evaluating the rationality of large language models (LLMs) across various domains. It includes a toolkit and experimental results to assess how LLMs compare to idealized human rationality.","authors":["Zhilun Zhou","Jing Yi Wang","Nicholas Sukiennik","Chen Gao","Fengli Xu","Yong Li","James Evans"],"categories":["cs.AI"],"affiliations":["Tsinghua University","University of Chicago","Santa Fe Institute"],"keywords":["large language models","rationality","artificial intelligence","benchmark","evaluation"],"language":"en","published_date":"2025-09-18T02:23:56Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14546v1"}
{"arxiv_id":"2509.14543v1","title":"Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the\n  Implicit Writing Styles of Everyday Authors","abstract":"As large language models (LLMs) become increasingly integrated into personal\nwriting tools, a critical question arises: can LLMs faithfully imitate an\nindividual's writing style from just a few examples? Personal style is often\nsubtle and implicit, making it difficult to specify through prompts yet\nessential for user-aligned generation. This work presents a comprehensive\nevaluation of state-of-the-art LLMs' ability to mimic personal writing styles\nvia in-context learning from a small number of user-authored samples. We\nintroduce an ensemble of complementary metrics-including authorship\nattribution, authorship verification, style matching, and AI detection-to\nrobustly assess style imitation. Our evaluation spans over 40000 generations\nper model across domains such as news, email, forums, and blogs, covering\nwriting samples from more than 400 real-world authors. Results show that while\nLLMs can approximate user styles in structured formats like news and email,\nthey struggle with nuanced, informal writing in blogs and forums. Further\nanalysis on various prompting strategies such as number of demonstrations\nreveal key limitations in effective personalization. Our findings highlight a\nfundamental gap in personalized LLM adaptation and the need for improved\ntechniques to support implicit, style-consistent generation. To aid future\nresearch and for reproducibility, we open-source our data and code.","summary":"This study evaluates the ability of large language models to imitate personal writing styles using few examples. Results indicate that while LLMs can mimic structured formats, they struggle with informal writing styles.","authors":["Zhengxiang Wang","Nafis Irtiza Tripto","Solha Park","Zhenzhen Li","Jiawei Zhou"],"categories":["cs.CL","cs.AI"],"affiliations":["Stony Brook University","The Pennsylvania State University","Bosch Center for AI"],"keywords":["large language models","writing style","personalization","style imitation","evaluation metrics"],"language":"en","published_date":"2025-09-18T02:18:49Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14543v1"}
{"arxiv_id":"2509.14537v1","title":"ClearFairy: Capturing Creative Workflows through Decision Structuring,\n  In-Situ Questioning, and Rationale Inference","abstract":"Capturing professionals' decision-making in creative workflows is essential\nfor reflection, collaboration, and knowledge sharing, yet existing methods\noften leave rationales incomplete and implicit decisions hidden. To address\nthis, we present CLEAR framework that structures reasoning into cognitive\ndecision steps-linked units of actions, artifacts, and self-explanations that\nmake decisions traceable. Building on this framework, we introduce ClearFairy,\na think-aloud AI assistant for UI design that detects weak explanations, asks\nlightweight clarifying questions, and infers missing rationales to ease the\nknowledge-sharing burden. In a study with twelve creative professionals, 85% of\nClearFairy's inferred rationales were accepted, increasing strong explanations\nfrom 14% to over 83% of decision steps without adding cognitive demand. The\ncaptured steps also enhanced generative AI agents in Figma, yielding\nnext-action predictions better aligned with professionals and producing more\ncoherent design outcomes. For future research on human knowledge-grounded\ncreative AI agents, we release a dataset of captured 417 decision steps.","summary":"The study presents ClearFairy, an AI assistant designed to enhance decision-making in creative workflows by structuring reasoning into traceable cognitive steps. It addresses the challenge of incomplete rationales and implicit decisions through in-situ questioning and workflow segmentation.","authors":["Kihoon Son","DaEun Choi","Tae Soo Kim","Young-Ho Kim","Sangdoo Yun","Juho Kim"],"categories":["cs.HC","cs.AI"],"affiliations":["KAIST","NAVER AI Lab"],"keywords":["creative workflows","decision-making","AI assistant","knowledge sharing","cognitive decision steps"],"language":"en","published_date":"2025-09-18T02:11:34Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14537v1"}
{"arxiv_id":"2509.14532v1","title":"Leveraging Artificial Intelligence as a Strategic Growth Catalyst for\n  Small and Medium-sized Enterprises","abstract":"Artificial Intelligence (AI) has transitioned from a futuristic concept\nreserved for large corporations to a present-day, accessible, and essential\ngrowth lever for Small and Medium-sized Enterprises (SMEs). For entrepreneurs\nand business leaders, strategic AI adoption is no longer an option but an\nimperative for competitiveness, operational efficiency, and long-term survival.\nThis report provides a comprehensive framework for SME leaders to navigate this\ntechnological shift, offering the foundational knowledge, business case,\npractical applications, and strategic guidance necessary to harness the power\nof AI. The quantitative evidence supporting AI adoption is compelling; 91% of\nSMEs using AI report that it directly boosts their revenue. Beyond top-line\ngrowth, AI drives profound operational efficiencies, with studies showing it\ncan reduce operational costs by up to 30% and save businesses more than 20\nhours of valuable time each month. This transformation is occurring within the\ncontext of a seismic economic shift; the global AI market is projected to surge\nfrom $233.46 Billion in 2024 to an astonishing $1.77 Trillion by 2032. This\npaper demystifies the core concepts of AI, presents a business case based on\nmarket data, details practical applications, and lays out a phased, actionable\nadoption strategy.","summary":"This report outlines how Artificial Intelligence serves as a crucial growth lever for Small and Medium-sized Enterprises, emphasizing its importance for competitiveness and operational efficiency. It provides a framework for SME leaders to adopt AI strategically, supported by compelling quantitative evidence.","authors":["Oluwatosin Agbaakin"],"categories":["cs.CY","cs.AI","econ.GN","q-fin.EC","J.1; K.4.3; I.2.7"],"affiliations":["Indiana University"],"keywords":["Artificial Intelligence","Small and Medium-sized Enterprises","Business Strategy","Digital Transformation","Machine Learning"],"language":"en","published_date":"2025-09-18T01:56:04Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14532v1"}
{"arxiv_id":"2509.14526v1","title":"Delta Knowledge Distillation for Large Language Models","abstract":"Knowledge distillation (KD) is a widely adopted approach for compressing\nlarge neural networks by transferring knowledge from a large teacher model to a\nsmaller student model. In the context of large language models, token level KD,\ntypically minimizing the KL divergence between student output distribution and\nteacher output distribution, has shown strong empirical performance. However,\nprior work assumes student output distribution and teacher output distribution\nshare the same optimal representation space, a premise that may not hold in\nmany cases. To solve this problem, we propose Delta Knowledge Distillation\n(Delta-KD), a novel extension of token level KD that encourages the student to\napproximate an optimal representation space by explicitly preserving the\ndistributional shift Delta introduced during the teacher's supervised\nfinetuning (SFT). Empirical results on ROUGE metrics demonstrate that Delta KD\nsubstantially improves student performance while preserving more of the\nteacher's knowledge.","summary":"This paper introduces Delta Knowledge Distillation (Delta-KD), a method that enhances knowledge transfer from large teacher models to smaller student models. Empirical results show that Delta-KD improves student performance while preserving the teacher's knowledge.","authors":["Yihan Cao","Yanbin Kang","Zhengming Xing","Ruijie Jiang"],"categories":["cs.CL","cs.AI","cs.LG"],"affiliations":["LinkedIn Corporation"],"keywords":["Knowledge Distillation","Large Language Models","Model Compression","Token-level KD","Delta-KD"],"language":"en","published_date":"2025-09-18T01:42:24Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14526v1"}
{"arxiv_id":"2509.14519v1","title":"BEACON: Behavioral Malware Classification with Large Language Model\n  Embeddings and Deep Learning","abstract":"Malware is becoming increasingly complex and widespread, making it essential\nto develop more effective and timely detection methods. Traditional static\nanalysis often fails to defend against modern threats that employ code\nobfuscation, polymorphism, and other evasion techniques. In contrast,\nbehavioral malware detection, which monitors runtime activities, provides a\nmore reliable and context-aware solution. In this work, we propose BEACON, a\nnovel deep learning framework that leverages large language models (LLMs) to\ngenerate dense, contextual embeddings from raw sandbox-generated behavior\nreports. These embeddings capture semantic and structural patterns of each\nsample and are processed by a one-dimensional convolutional neural network (1D\nCNN) for multi-class malware classification. Evaluated on the Avast-CTU Public\nCAPE Dataset, our framework consistently outperforms existing methods,\nhighlighting the effectiveness of LLM-based behavioral embeddings and the\noverall design of BEACON for robust malware classification.","summary":"This work proposes BEACON, a deep learning framework that uses large language models to enhance behavioral malware detection. The framework outperforms existing methods by leveraging contextual embeddings for robust malware classification.","authors":["Wadduwage Shanika Perera","Haodi Jiang"],"categories":["cs.LG","cs.AI","cs.CR"],"affiliations":["Sam Houston State University"],"keywords":["Malware classification","Large language model embeddings","Deep learning","Behavioral analysis","Dynamic detection"],"language":"en","published_date":"2025-09-18T01:24:12Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14519v1"}
{"arxiv_id":"2509.14507v1","title":"DeKeyNLU: Enhancing Natural Language to SQL Generation through Task\n  Decomposition and Keyword Extraction","abstract":"Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that\nsimplifies database access for non-technical users by converting natural\nlanguage queries into SQL commands. Recent advancements, particularly those\nintegrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)\nreasoning, have made significant strides in enhancing NL2SQL performance.\nHowever, challenges such as inaccurate task decomposition and keyword\nextraction by LLMs remain major bottlenecks, often leading to errors in SQL\ngeneration. While existing datasets aim to mitigate these issues by fine-tuning\nmodels, they struggle with over-fragmentation of tasks and lack of\ndomain-specific keyword annotations, limiting their effectiveness. To address\nthese limitations, we present DeKeyNLU, a novel dataset which contains 1,500\nmeticulously annotated QA pairs aimed at refining task decomposition and\nenhancing keyword extraction precision for the RAG pipeline. Fine-tuned with\nDeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three\ndistinct modules for user question understanding, entity retrieval, and\ngeneration to improve SQL generation accuracy. We benchmarked multiple model\nconfigurations within DeKeySQL RAG pipeline. Experimental results demonstrate\nthat fine-tuning with DeKeyNLU significantly improves SQL generation accuracy\non both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.","summary":"The paper presents DeKeyNLU, a dataset aimed at improving Natural Language to SQL (NL2SQL) systems by refining task decomposition and enhancing keyword extraction. Experimental results show that fine-tuning with DeKeyNLU significantly boosts SQL generation accuracy.","authors":["Jian Chen","Zhenyan Chen","Xuming Hu","Peilin Zhou","Yining Hua","Han Fang","Cissy Hing Yee Choy","Xinmei Ke","Jingfeng Luo","Zixuan Yuan"],"categories":["cs.AI","cs.CL"],"affiliations":["The Hong Kong University of Science and Technology","HSBC","South China University of Technology","Harvard University","Chicago University"],"keywords":["Natural Language Processing","SQL Generation","Task Decomposition","Keyword Extraction","Dataset"],"language":"en","published_date":"2025-09-18T00:47:56Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14507v1"}
{"arxiv_id":"2509.14504v1","title":"Introducing OmniGEC: A Silver Multilingual Dataset for Grammatical Error\n  Correction","abstract":"In this paper, we introduce OmniGEC, a collection of multilingual\nsilver-standard datasets for the task of Grammatical Error Correction (GEC),\ncovering eleven languages: Czech, English, Estonian, German, Greek, Icelandic,\nItalian, Latvian, Slovene, Swedish, and Ukrainian. These datasets facilitate\nthe development of multilingual GEC solutions and help bridge the data gap in\nadapting English GEC solutions to multilingual GEC. The texts in the datasets\noriginate from three sources: Wikipedia edits for the eleven target languages,\nsubreddits from Reddit in the eleven target languages, and the Ukrainian-only\nUberText 2.0 social media corpus. While Wikipedia edits were derived from\nhuman-made corrections, the Reddit and UberText 2.0 data were automatically\ncorrected with the GPT-4o-mini model. The quality of the corrections in the\ndatasets was evaluated both automatically and manually. Finally, we fine-tune\ntwo open-source large language models - Aya-Expanse (8B) and Gemma-3 (12B) - on\nthe multilingual OmniGEC corpora and achieve state-of-the-art (SOTA) results\nfor paragraph-level multilingual GEC. The dataset collection and the\nbest-performing models are available on Hugging Face.","summary":"This paper introduces OmniGEC, a multilingual dataset for Grammatical Error Correction, covering eleven languages. The datasets aim to enhance multilingual GEC solutions and bridge the data gap in adapting English GEC methods.","authors":["Roman Kovalchuk","Mariana Romanyshyn","Petro Ivaniuk"],"categories":["cs.CL","cs.AI","cs.LG"],"affiliations":["Ukrainian Catholic University","Softserve","Grammarly"],"keywords":["Grammatical Error Correction","multilingual","datasets","NLP","language models"],"language":"en","published_date":"2025-09-18T00:35:31Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14504v1"}
{"arxiv_id":"2509.14485v1","title":"Beyond the high score: Prosocial ability profiles of multi-agent\n  populations","abstract":"The development and evaluation of social capabilities in AI agents require\ncomplex environments where competitive and cooperative behaviours naturally\nemerge. While game-theoretic properties can explain why certain teams or agent\npopulations outperform others, more abstract behaviours, such as convention\nfollowing, are harder to control in training and evaluation settings. The\nMelting Pot contest is a social AI evaluation suite designed to assess the\ncooperation capabilities of AI systems. In this paper, we apply a Bayesian\napproach known as Measurement Layouts to infer the capability profiles of\nmulti-agent systems in the Melting Pot contest. We show that these capability\nprofiles not only predict future performance within the Melting Pot suite but\nalso reveal the underlying prosocial abilities of agents. Our analysis\nindicates that while higher prosocial capabilities sometimes correlate with\nbetter performance, this is not a universal trend-some lower-scoring agents\nexhibit stronger cooperation abilities. Furthermore, we find that\ntop-performing contest submissions are more likely to achieve high scores in\nscenarios where prosocial capabilities are not required. These findings,\ntogether with reports that the contest winner used a hard-coded solution\ntailored to specific environments, suggest that at least one top-performing\nteam may have optimised for conditions where cooperation was not necessary,\npotentially exploiting limitations in the evaluation framework. We provide\nrecommendations for improving the annotation of cooperation demands and propose\nfuture research directions to account for biases introduced by different\ntesting environments. Our results demonstrate that Measurement Layouts offer\nboth strong predictive accuracy and actionable insights, contributing to a more\ntransparent and generalisable approach to evaluating AI systems in complex\nsocial settings.","summary":"This paper applies a Bayesian approach to infer the prosocial ability profiles of multi-agent systems in the Melting Pot contest, revealing insights into their cooperation capabilities. The findings suggest that higher prosocial abilities do not always correlate with better performance, highlighting the complexity of AI evaluation.","authors":["Marko Tesic","Yue Zhao","Joel Z. Leibo","Rakshit S. Trivedi","Jose Hernandez-Orallo"],"categories":["cs.AI"],"affiliations":["University of Cambridge","Northwestern Polytechnical University","Google DeepMind","MIT","Universitat Politècnica de València"],"keywords":["AI evaluation","prosocial abilities","multi-agent systems","Measurement Layouts","cooperation"],"language":"en","published_date":"2025-09-17T23:29:39Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14485v1"}
{"arxiv_id":"2509.14480v1","title":"Process-Supervised Reinforcement Learning for Interactive Multimodal\n  Tool-Use Agents","abstract":"Effective interactive tool use requires agents to master Tool Integrated\nReasoning (TIR): a complex process involving multi-turn planning and\nlong-context dialogue management. To train agents for this dynamic process,\nparticularly in multi-modal contexts, we introduce a sandbox environment for\nreinforcement learning (RL) that supports interleaved speech-text rollouts. Our\ncore strategy, Turn-level Adjudicated Reinforcement Learning (TARL), addresses\nthe challenge of credit assignment in long-horizon tasks by employing a Large\nLanguage Model (LLM) as a judge to provide turn-level evaluation. To enhance\nexploration, we integrate a mixed-task training curriculum with mathematical\nreasoning problems. This unified approach boosts the task pass rate on the\ntext-based $\\tau$-bench by over 6% compared to strong RL baselines. Crucially,\nwe demonstrate our framework's suitability for fine-tuning a multi-modal\nfoundation model for agentic tasks. By training a base multi-modal LLM on\ninterleaved speech-text rollouts, we equip it with tool-use abilities, paving\nthe way for more natural, voice-driven interactive agents.","summary":"This paper presents a novel approach for training interactive agents in multimodal contexts using reinforcement learning. The proposed method enhances tool-use abilities through a sandbox environment and a mixed-task training curriculum.","authors":["Weiting Tan","Xinghua Qu","Ming Tu","Meng Ge","Andy T. Liu","Philipp Koehn","Lu Lu"],"categories":["cs.CL","cs.AI","cs.MA"],"affiliations":["ByteDance Seed","Johns Hopkins University"],"keywords":["Reinforcement Learning","Multimodal","Tool Use","Dialogue Management","Large Language Model"],"language":"en","published_date":"2025-09-17T23:25:00Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14480v1"}
{"arxiv_id":"2509.14476v1","title":"AToken: A Unified Tokenizer for Vision","abstract":"We present AToken, the first unified visual tokenizer that achieves both\nhigh-fidelity reconstruction and semantic understanding across images, videos,\nand 3D assets. Unlike existing tokenizers that specialize in either\nreconstruction or understanding for single modalities, AToken encodes these\ndiverse visual inputs into a shared 4D latent space, unifying both tasks and\nmodalities in a single framework. Specifically, we introduce a pure transformer\narchitecture with 4D rotary position embeddings to process visual inputs of\narbitrary resolutions and temporal durations. To ensure stable training, we\nintroduce an adversarial-free training objective that combines perceptual and\nGram matrix losses, achieving state-of-the-art reconstruction quality. By\nemploying a progressive training curriculum, AToken gradually expands from\nsingle images, videos, and 3D, and supports both continuous and discrete latent\ntokens. AToken achieves 0.21 rFID with 82.2% ImageNet accuracy for images, 3.01\nrFVD with 32.6% MSRVTT retrieval for videos, and 28.19 PSNR with 90.9%\nclassification accuracy for 3D. In downstream applications, AToken enables both\nvisual generation tasks (e.g., image generation with continuous and discrete\ntokens, text-to-video generation, image-to-3D synthesis) and understanding\ntasks (e.g., multimodal LLMs), achieving competitive performance across all\nbenchmarks. These results shed light on the next-generation multimodal AI\nsystems built upon unified visual tokenization.","summary":"ATOKEN is a unified visual tokenizer that integrates high-fidelity reconstruction and semantic understanding across various visual modalities. It employs a transformer architecture to process diverse visual inputs, achieving state-of-the-art performance in both generation and understanding tasks.","authors":["Jiasen Lu","Liangchen Song","Mingze Xu","Byeongjoo Ahn","Yanjun Wang","Chen Chen","Afshin Dehghan","Yinfei Yang"],"categories":["cs.CV","cs.AI","cs.MM"],"affiliations":["Apple"],"keywords":["visual tokenizer","semantic understanding","high-fidelity reconstruction","transformer architecture","multimodal AI"],"language":"en","published_date":"2025-09-17T23:11:18Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14476v1"}
{"arxiv_id":"2509.14474v1","title":"From Mimicry to True Intelligence (TI) -- A New Paradigm for Artificial\n  General Intelligence","abstract":"The debate around Artificial General Intelligence (AGI) remains open due to\ntwo fundamentally different goals: replicating human-like performance versus\nreplicating human-like cognitive processes. We argue that current\nperformance-based definitions are inadequate because they provide no clear,\nmechanism-focused roadmap for research, and they fail to properly define the\nqualitative nature of genuine intelligence. Drawing inspiration from the human\nbrain, we propose a new paradigm that shifts the focus from external mimicry to\nthe development of foundational cognitive architectures. We define True\nIntelligence (TI) as a system characterized by six core components: embodied\nsensory fusion, core directives, dynamic schemata creation, a\nhighly-interconnected multi-expert architecture, an orchestration layer, and\nlastly, the unmeasurable quality of Interconnectedness, which we hypothesize\nresults in consciousness and a subjective experience. We propose a practical,\nfive-level taxonomy of AGI based on the number of the first five measurable\ncomponents a system exhibits. This framework provides a clear path forward with\ndevelopmental milestones that directly address the challenge of building\ngenuinely intelligent systems. We contend that once a system achieves Level-5\nAGI by implementing all five measurable components, the difference between it\nand TI remains as a purely philosophical debate. For practical purposes - and\ngiven theories indicate consciousness is an emergent byproduct of integrated,\nhigher-order cognition - we conclude that a fifth-level AGI is functionally and\npractically equivalent to TI. This work synthesizes diverse insights from\nanalytical psychology, schema theory, metacognition, modern brain architectures\nand latest works in AI to provide the first holistic, mechanism-based\ndefinition of AGI that offers a clear and actionable path for the research\ncommunity.","summary":"The paper proposes a new paradigm for Artificial General Intelligence (AGI) that emphasizes foundational cognitive architectures over mere performance mimicry. It introduces True Intelligence (TI) and a five-level taxonomy for AGI development, aiming to clarify the path for creating genuinely intelligent systems.","authors":["Meltem Subasioglu","Nevzat Subasioglu"],"categories":["cs.AI","cs.CY"],"affiliations":[],"keywords":["Artificial General Intelligence","True Intelligence","Cognitive Science","Consciousness","AI Ethics"],"language":"en","published_date":"2025-09-17T23:08:36Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14474v1"}
{"arxiv_id":"2509.14456v1","title":"Correct-Detect: Balancing Performance and Ambiguity Through the Lens of\n  Coreference Resolution in LLMs","abstract":"Large Language Models (LLMs) are intended to reflect human linguistic\ncompetencies. But humans have access to a broad and embodied context, which is\nkey in detecting and resolving linguistic ambiguities, even in isolated text\nspans. A foundational case of semantic ambiguity is found in the task of\ncoreference resolution: how is a pronoun related to an earlier person mention?\nThis capability is implicit in nearly every downstream task, and the presence\nof ambiguity at this level can alter performance significantly. We show that\nLLMs can achieve good performance with minimal prompting in both coreference\ndisambiguation and the detection of ambiguity in coreference, however, they\ncannot do both at the same time. We present the CORRECT-DETECT trade-off:\nthough models have both capabilities and deploy them implicitly, successful\nperformance balancing these two abilities remains elusive.","summary":"This study explores the performance of large language models in coreference resolution and ambiguity detection. It highlights the trade-off between accurately resolving unambiguous references and detecting ambiguity.","authors":["Amber Shore","Russell Scheinberg","Ameeta Agrawal","So Young Lee"],"categories":["cs.CL","cs.AI"],"affiliations":["Portland State University","Miami University"],"keywords":["coreference resolution","ambiguity detection","large language models","semantic ambiguity","disambiguation"],"language":"en","published_date":"2025-09-17T22:12:30Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14456v1"}
{"arxiv_id":"2509.14448v1","title":"VCBench: Benchmarking LLMs in Venture Capital","abstract":"Benchmarks such as SWE-bench and ARC-AGI demonstrate how shared datasets\naccelerate progress toward artificial general intelligence (AGI). We introduce\nVCBench, the first benchmark for predicting founder success in venture capital\n(VC), a domain where signals are sparse, outcomes are uncertain, and even top\ninvestors perform modestly. At inception, the market index achieves a precision\nof 1.9%. Y Combinator outperforms the index by a factor of 1.7x, while tier-1\nfirms are 2.9x better. VCBench provides 9,000 anonymized founder profiles,\nstandardized to preserve predictive features while resisting identity leakage,\nwith adversarial tests showing more than 90% reduction in re-identification\nrisk. We evaluate nine state-of-the-art large language models (LLMs).\nDeepSeek-V3 delivers over six times the baseline precision, GPT-4o achieves the\nhighest F0.5, and most models surpass human benchmarks. Designed as a public\nand evolving resource available at vcbench.com, VCBench establishes a\ncommunity-driven standard for reproducible and privacy-preserving evaluation of\nAGI in early-stage venture forecasting.","summary":"VCBench is introduced as the first benchmark for predicting founder success in venture capital, addressing challenges of sparse signals and uncertain outcomes. The dataset includes 9,000 anonymized founder profiles and evaluates nine state-of-the-art large language models.","authors":["Rick Chen","Joseph Ternasky","Afriyie Samuel Kwesi","Ben Griffin","Aaron Ontoyin Yin","Zakari Salifu","Kelvin Amoaba","Xianling Mu","Fuat Alican","Yigit Ihlamur"],"categories":["cs.AI"],"affiliations":["University of Oxford","Vela Research"],"keywords":["venture capital","benchmarking","founder success","large language models","artificial general intelligence"],"language":"en","published_date":"2025-09-17T21:56:48Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14448v1"}
{"arxiv_id":"2509.14438v1","title":"Simulating a Bias Mitigation Scenario in Large Language Models","abstract":"Large Language Models (LLMs) have fundamentally transformed the field of\nnatural language processing; however, their vulnerability to biases presents a\nnotable obstacle that threatens both fairness and trust. This review offers an\nextensive analysis of the bias landscape in LLMs, tracing its roots and\nexpressions across various NLP tasks. Biases are classified into implicit and\nexplicit types, with particular attention given to their emergence from data\nsources, architectural designs, and contextual deployments. This study advances\nbeyond theoretical analysis by implementing a simulation framework designed to\nevaluate bias mitigation strategies in practice. The framework integrates\nmultiple approaches including data curation, debiasing during model training,\nand post-hoc output calibration and assesses their impact in controlled\nexperimental settings. In summary, this work not only synthesizes existing\nknowledge on bias in LLMs but also contributes original empirical validation\nthrough simulation of mitigation strategies.","summary":"This study analyzes biases in Large Language Models and implements a simulation framework to evaluate bias mitigation strategies. It classifies biases and assesses various approaches to address them in controlled settings.","authors":["Kiana Kiashemshaki","Mohammad Jalili Torkamani","Negin Mahmoudi","Meysam Shirdel Bilehsavar"],"categories":["cs.CL","cs.AI","I.2"],"affiliations":["Bowling Green State University","University of Nebraska–Lincoln","Stevens Institute of Technology","University of South Carolina"],"keywords":["Bias Mitigation","Large Language Models","Natural Language Processing","Debiasing","Simulation Framework"],"language":"en","published_date":"2025-09-17T21:22:33Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14438v1"}
{"arxiv_id":"2509.14436v1","title":"When Content is Goliath and Algorithm is David: The Style and Semantic\n  Effects of Generative Search Engine","abstract":"Generative search engines (GEs) leverage large language models (LLMs) to\ndeliver AI-generated summaries with website citations, establishing novel\ntraffic acquisition channels while fundamentally altering the search engine\noptimization landscape. To investigate the distinctive characteristics of GEs,\nwe collect data through interactions with Google's generative and conventional\nsearch platforms, compiling a dataset of approximately ten thousand websites\nacross both channels. Our empirical analysis reveals that GEs exhibit\npreferences for citing content characterized by significantly higher\npredictability for underlying LLMs and greater semantic similarity among\nselected sources. Through controlled experiments utilizing retrieval augmented\ngeneration (RAG) APIs, we demonstrate that these citation preferences emerge\nfrom intrinsic LLM tendencies to favor content aligned with their generative\nexpression patterns. Motivated by applications of LLMs to optimize website\ncontent, we conduct additional experimentation to explore how LLM-based content\npolishing by website proprietors alters AI summaries, finding that such\npolishing paradoxically enhances information diversity within AI summaries.\nFinally, to assess the user-end impact of LLM-induced information increases, we\ndesign a generative search engine and recruit Prolific participants to conduct\na randomized controlled experiment involving an information-seeking and writing\ntask. We find that higher-educated users exhibit minimal changes in their final\noutputs' information diversity but demonstrate significantly reduced task\ncompletion time when original sites undergo polishing. Conversely,\nlower-educated users primarily benefit through enhanced information density in\ntheir task outputs while maintaining similar completion times across\nexperimental groups.","summary":"This study investigates the characteristics of generative search engines and their impact on information diversity and task completion times for users with varying education levels. The findings highlight the implications for stakeholders in the evolving search ecosystem.","authors":["Lijia Ma","Juan Qin","Xingchen Xu","Yong Tan"],"categories":["cs.IR","cs.AI","H.3.3; I.2.7; J.4"],"affiliations":["University of North Carolina at Charlotte","University of Science and Technology of China","University of Washington"],"keywords":["Generative Search Engine","Generative AI","AI Summary","RAG","Search Engine Optimization"],"language":"en","published_date":"2025-09-17T21:19:13Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14436v1"}
{"arxiv_id":"2509.14404v1","title":"A Taxonomy of Prompt Defects in LLM Systems","abstract":"Large Language Models (LLMs) have become key components of modern software,\nwith prompts acting as their de-facto programming interface. However, prompt\ndesign remains largely empirical and small mistakes can cascade into\nunreliable, insecure, or inefficient behavior. This paper presents the first\nsystematic survey and taxonomy of prompt defects, recurring ways that prompts\nfail to elicit their intended behavior from LLMs. We organize defects along six\ndimensions: (1) Specification and Intent, (2) Input and Content, (3) Structure\nand Formatting, (4) Context and Memory, (5) Performance and Efficiency, and (6)\nMaintainability and Engineering. Each dimension is refined into fine-grained\nsubtypes, illustrated with concrete examples and root cause analysis. Grounded\nin software engineering principles, we show how these defects surface in real\ndevelopment workflows and examine their downstream effects. For every subtype,\nwe distill mitigation strategies that span emerging prompt engineering\npatterns, automated guardrails, testing harnesses, and evaluation frameworks.\nWe then summarize these strategies in a master taxonomy that links defect,\nimpact, and remedy. We conclude with open research challenges and a call for\nrigorous engineering-oriented methodologies to ensure that LLM-driven systems\nare dependable by design.","summary":"This paper presents a systematic survey and taxonomy of prompt defects in Large Language Models (LLMs), organizing them along six dimensions. It also distills mitigation strategies and highlights open research challenges for dependable LLM-driven systems.","authors":["Haoye Tian","Chong Wang","BoYang Yang","Lyuye Zhang","Yang Liu"],"categories":["cs.SE","cs.AI","cs.CL","cs.PL"],"affiliations":["Nanyang Technological University","Jisuan Institute of Technology","Beijing JudaoYouda Network Technology Co. Ltd."],"keywords":["Large Language Models","prompt defects","taxonomy","software engineering","mitigation strategies"],"language":"en","published_date":"2025-09-17T20:11:22Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14404v1"}
{"arxiv_id":"2509.14391v1","title":"Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in\n  Quantized Long-Context LLMs","abstract":"Extending LLM context windows is crucial for long range tasks. RoPE-based\nposition interpolation (PI) methods like linear and frequency-aware scaling\nextend input lengths without retraining, while post-training quantization (PTQ)\nenables practical deployment. We show that combining PI with PTQ degrades\naccuracy due to coupled effects long context aliasing, dynamic range dilation,\naxis grid anisotropy, and outlier shifting that induce position-dependent logit\nnoise. We provide the first systematic analysis of PI plus PTQ and introduce\ntwo diagnostics: Interpolation Pressure (per-band phase scaling sensitivity)\nand Tail Inflation Ratios (outlier shift from short to long contexts). To\naddress this, we propose Q-ROAR, a RoPE-aware, weight-only stabilization that\ngroups RoPE dimensions into a few frequency bands and performs a small search\nover per-band scales for W_Q,W_K, with an optional symmetric variant to\npreserve logit scale. The diagnostics guided search uses a tiny long-context\ndev set and requires no fine-tuning, kernel, or architecture changes.\nEmpirically, Q-ROAR recovers up to 0.7% accuracy on standard tasks and reduces\nGovReport perplexity by more than 10%, while preserving short-context\nperformance and compatibility with existing inference stacks.","summary":"This paper presents Q-ROAR, a method to stabilize RoPE-based position interpolation in quantized long-context LLMs. It addresses accuracy degradation caused by the coupling of position interpolation and post-training quantization.","authors":["Ye Qiao","Sitao Huang"],"categories":["cs.LG","cs.AI"],"affiliations":["University of California, Irvine"],"keywords":["Long-Context LLMs","RoPE","Position Interpolation","Post-Training Quantization","Q-ROAR"],"language":"en","published_date":"2025-09-17T19:50:16Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14391v1"}
{"arxiv_id":"2509.14388v1","title":"eIQ Neutron: Redefining Edge-AI Inference with Integrated NPU and\n  Compiler Innovations","abstract":"Neural Processing Units (NPUs) are key to enabling efficient AI inference in\nresource-constrained edge environments. While peak tera operations per second\n(TOPS) is often used to gauge performance, it poorly reflects real-world\nperformance and typically rather correlates with higher silicon cost. To\naddress this, architects must focus on maximizing compute utilization, without\nsacrificing flexibility. This paper presents the eIQ Neutron efficient-NPU,\nintegrated into a commercial flagship MPU, alongside co-designed compiler\nalgorithms. The architecture employs a flexible, data-driven design, while the\ncompiler uses a constrained programming approach to optimize compute and data\nmovement based on workload characteristics. Compared to the leading embedded\nNPU and compiler stack, our solution achieves an average speedup of 1.8x (4x\npeak) at equal TOPS and memory resources across standard AI-benchmarks. Even\nagainst NPUs with double the compute and memory resources, Neutron delivers up\nto 3.3x higher performance.","summary":"The paper presents eIQ Neutron, an efficient NPU architecture integrated with a co-designed compiler for optimized edge-AI inference. It achieves significant performance improvements over existing NPUs while maintaining cost-efficiency.","authors":["Lennart Bamberg","Filippo Minnella","Roberto Bosio","Fabrizio Ottati","Yuebin Wang","Jongmin Lee","Luciano Lavagno","Adam Fuks"],"categories":["cs.AR","cs.AI","cs.LG"],"affiliations":["NXP Semiconductors","Politecnico di Torino"],"keywords":["Edge AI","Neural Processing Unit","Compiler","Hardware-Software Co-Design","Performance Optimization"],"language":"en","published_date":"2025-09-17T19:45:51Z","url_pdf":"http:\/\/arxiv.org\/pdf\/2509.14388v1"}
